#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass IEEEtran
\begin_preamble
\usepackage{algorithm}
\usepackage{algpseudocode}


\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\DeclareMathOperator*{\st}{s.t.\,}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\sign}{sign}

% Stretch cells vertically
\usepackage{array}
%\renewcommand*\arraystretch{1.5}
%\setlength{\extrarowheight}{2pt}

\usepackage{babel}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-15
\fontencoding T1
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
ProxiSART: A Proximal Framework for Robust X-Ray Tomography Reconstruction
 using SART
\end_layout

\begin_layout Author
Mohamed Aly, 
\begin_inset Flex Flex:IEEE membership
status collapsed

\begin_layout Plain Layout
Member, IEEE
\end_layout

\end_inset

,
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
M.
 Aly is with the Visual Computing Center, KAUST, KSA
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% and
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% the Computer Eng.
 Dept, Cairo University, Egypt%
\end_layout

\end_inset


\end_layout

\end_inset

, Guangming Zang, 
\begin_inset Flex Flex:IEEE membership
status collapsed

\begin_layout Plain Layout
Student Member, IEEE
\end_layout

\end_inset

, 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
G.
 Zang is with the Visual Computing Center, KAUST, KSA
\end_layout

\end_inset

 Wolfgang Heidrich, 
\begin_inset Flex Flex:IEEE membership
status collapsed

\begin_layout Plain Layout
Member, IEEE
\end_layout

\end_inset

, 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
W.
 Heidrich is with the Visual Computing Center, KAUST, KSA
\end_layout

\end_inset

 and Peter Wonka, 
\begin_inset Flex Flex:IEEE membership
status collapsed

\begin_layout Plain Layout
Member, IEEE
\end_layout

\end_inset

, 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
P.
 Wonka is with the Visual Computing Center, KAUST, KSA
\end_layout

\end_inset

 
\end_layout

\begin_layout Abstract
We present ProxiSART, a flexible proximal framework for robust X-ray tomographic
 reconstruction based on the Simultaneous Algebraic Reconstruction Technique
 (SART).
 We conduct a thorough comparison between different iterative reconstruction
 methods and establish that SART is the best algorithm in terms of reconstructio
n quality for sparse-view and noisy-measurement situations.
 We then focus on SART and derive its proximal operator.
 We show the flexibility of the framework by deriving solvers for different
 data terms including L1, L2, and weighted L2; and by plugging in different
 powerful regularizers.
 We compare our framework to state-of-the-art methods, and show superior
 quality on both synthetic and real datasets.
\end_layout

\begin_layout Keywords
Image reconstruction, X-ray imaging and computed tomography, Simultaneous
 Algebraic Reconstruction Technique, SART, Proximal Algorithms, Cone beam
 X-ray tomography 
\end_layout

\begin_layout Section
Introduction
\begin_inset CommandInset label
LatexCommand label
name "sec:Introduction"

\end_inset


\end_layout

\begin_layout Standard
Reducing the dosage in X-ray tomography is a very important issue in medical
 applications, since long term exposure to X-rays can have adverse health
 effects.
 This can be done in at least two ways: (a) reducing the X-ray beam power,
 which leads to increased measurement noise at the detectors; or (b) acquiring
 fewer projections to reduce the acquisition time 
\begin_inset CommandInset citation
LatexCommand cite
key "herman2009fundamentals"

\end_inset

.
 This makes the reconstruction problem even more ill-posed, since less informati
on is collected from the volume to be reconstructed; and one has to use
 non-linear regularizers (priors) to achieve a reasonable result.
 This is typically done using iterative solvers 
\begin_inset CommandInset citation
LatexCommand cite
key "thibault2007three,zhang2014model"

\end_inset

.
\end_layout

\begin_layout Standard
Iterative algorithms for X-ray tomography reconstruction have been around
 for years.
 In fact, one of the first implemented tomography reconstruction algorithm
 was an iterative one, the Algebraic Reconstruction Technique (ART) 
\begin_inset CommandInset citation
LatexCommand cite
key "kak2001principles,gordon1970algebraic,gordon1971reconstruction"

\end_inset

.
 However, non-iterative, transform-based algorithms, such as the filtered
 back projection (FBP) 
\begin_inset CommandInset citation
LatexCommand cite
key "ramachandran1971three,shepp1974fourier,feldkamp1984practical"

\end_inset

, have been more popular due to their speed and low computational cost.
 In fact, most commercial X-ray CT scanners employ some variant of FBP in
 their reconstruction software 
\begin_inset CommandInset citation
LatexCommand cite
key "pan2009commercial"

\end_inset

.
 Recently, interest has been ignited again in iterative algorithms because,
 although they are more computationally demanding, they are much more flexible
 and yield superior reconstruction quality by employing powerful priors.
 
\end_layout

\begin_layout Standard
Thus, in this paper, we study iterative reconstruction techniques.
 We conduct a thorough comparison of the famous iterative algorithms including
 SART (Simultaneous Algebraic Reconstruction Technique) 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset

, ART 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset

, SIRT (Simultaneous Iterative Reconstruction Technique) 
\begin_inset CommandInset citation
LatexCommand cite
key "gilbert1972iterative"

\end_inset

, BSSART (Block Simplified SART) 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset

, BICAV (Block Iterative Component Averaging) 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2001bicav"

\end_inset

, Conjugate Gradient 
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical"

\end_inset

, and OS-SQS (Ordered-Subset Separable Quadratic Surrogates) 
\begin_inset CommandInset citation
LatexCommand cite
key "depierro1994modified,hudson1994accelerated,erdogan1999ordered,kim2013accelerating,nien2015fast"

\end_inset

.
 We establish that SART 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset

 provides the best performance in the sparse view and noisy measurements
 situations.
 This motivates us to focus on SART for the rest of our development.
\end_layout

\begin_layout Standard
We then describe our framework, which is based on using proximal algorithms
 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2011distributed,parikh2013proximal"

\end_inset

 together with SART.
 We derive proximal operators for SART, BICAV, and OS-SQS, and show how
 to use these proximal operators to minimize different data fitting terms,
 including least squares (LS) that assumes a Gaussian noise model, weighted
 least squares (WLS) that assumes an approximation to a Poisson noise model
 
\begin_inset CommandInset citation
LatexCommand cite
key "clinthorne1993preconditioning"

\end_inset

, and least absolute deviation (LAD) 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2012convex"

\end_inset

.
 We compare the proximal operators using a Total Variation (TV) prior 
\begin_inset CommandInset citation
LatexCommand cite
key "rudin1992nonlinear"

\end_inset

 and establish that the SART proximal operator provides the best performance.
 
\end_layout

\begin_layout Standard
Finally we compare our framework to state of the art methods, namely the
 Augmented Lagrangian method from 
\begin_inset CommandInset citation
LatexCommand cite
key "ramani2012splitting"

\end_inset

 and the OS-SQS momentum method from 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2015combining"

\end_inset

, and show that our framework gives superior reconstruction quality.
\end_layout

\begin_layout Standard
In summary, we provide the following contributions:
\end_layout

\begin_layout Enumerate
We perform a thorough experimental comparison of famous iterative reconstruction
 methods.
\end_layout

\begin_layout Enumerate
We derive proximal operators for SART, BICAV, and OS-SQS, and compare them.
\end_layout

\begin_layout Enumerate
We derive solvers for different data terms, namely LS, WLS, and LAD, using
 the derived proximal operator.
\end_layout

\begin_layout Enumerate
We compare our framework to state of the art methods and show that it produces
 superior reconstructions.
\end_layout

\begin_layout Enumerate
We make our code, which is based on the ASTRA toolbox 
\begin_inset CommandInset citation
LatexCommand cite
key "van2015astra"

\end_inset

, publicly available.
\end_layout

\begin_layout Section
Related Work
\begin_inset CommandInset label
LatexCommand label
name "sec:Related-Work"

\end_inset


\end_layout

\begin_layout Standard
There are two general approaches for X-ray tomography reconstruction: transform-
based methods and iterative methods 
\begin_inset CommandInset citation
LatexCommand cite
key "kak2001principles,herman2009fundamentals"

\end_inset

.
 Transform methods rely on the Radon transform and its inverse introduced
 in 1917.
 The most widely used reconstruction method is the Filtered Backprojection
 (FBP) algorithm introduced 
\begin_inset CommandInset citation
LatexCommand cite
key "herman2009fundamentals,kak2001principles"

\end_inset

.
 Transform methods are usually viewed as much faster than iterative methods,
 and have therefore been the method of choice for X-ray scanner manufacturers
 
\begin_inset CommandInset citation
LatexCommand cite
key "pan2009commercial"

\end_inset

.
\end_layout

\begin_layout Standard
Iterative methods on the other hand use algebraic techniques to solve the
 reconstruction problem.
 They generally model the problem as a linear system and solve it using
 established numerical methods 
\begin_inset CommandInset citation
LatexCommand cite
key "herman2009fundamentals"

\end_inset

.
 ART, and its many variants, are among the best known iterative reconstruction
 algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "gordon1970algebraic,lent1977convergent,shepp1982maximum,censor1983finite,andersen1984simultaneous,andersen1989algebraic"

\end_inset

.
 They use variations of the projection method of Kaczmarz 
\begin_inset CommandInset citation
LatexCommand cite
key "kaczmarz1937angenaherte"

\end_inset

 and have modest memory requirements, and have been shown to yield better
 reconstruction results than transform methods.
 They are matrix free, and work without having to explicitly store the system
 matrix.
 OS-SQS and related methods 
\begin_inset CommandInset citation
LatexCommand cite
key "depierro1994modified,hudson1994accelerated,erdogan1999ordered,kim2013accelerating,nien2015fast"

\end_inset

 are closely related to ART and have similar properties to SIRT 
\begin_inset CommandInset citation
LatexCommand cite
key "gregor2015comparison"

\end_inset

.
 The have also been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2015combining"

\end_inset

 to be accelerated using momentum techniques.
\end_layout

\begin_layout Standard
Iterative methods provide more flexibility in incorporating prior information
 into the reconstruction process.
 For example, instead of assuming a Gaussian noise model and minimizing
 a least squares data term, one can easily use iterative methods with other
 noise models.
 For example, a Poisson noise model 
\begin_inset CommandInset citation
LatexCommand cite
key "clinthorne1993preconditioning,depierro1994modified,elbakri2002statistical,wang2006penalized,thibault2007three"

\end_inset

.
 boils down to solving WLS problem instead.
 Priors are also easy to use with iterative methods.
 For example, the Total Variation 
\begin_inset CommandInset citation
LatexCommand cite
key "rudin1992nonlinear"

\end_inset

 prior has been used for tomography reconstruction 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2008image,mory2012ecg"

\end_inset

.
\end_layout

\begin_layout Standard
Proximal algorithms have been widely used in many problems in machine learning
 and signal processing 
\begin_inset CommandInset citation
LatexCommand cite
key "bauschke2011convex,combettes2011proximal,boyd2011distributed,parikh2013proximal"

\end_inset

.
 They have also been used in tomography reconstruction.
 For example, 
\begin_inset CommandInset citation
LatexCommand cite
key "mory2012ecg"

\end_inset

 used the Alternating Direction Method of Multipliers (ADMM) 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2011distributed"

\end_inset

 with total variation prior, where the data term was optimized using CG
 
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2012convex"

\end_inset

 discussed using the Chambolle-Pock algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "chambolle2011first"

\end_inset

 for tomography reconstruction with different priors.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ramani2012splitting"

\end_inset

 used ADMM with Preconditioned CG 
\begin_inset CommandInset citation
LatexCommand cite
key "nocedal2006numerical"

\end_inset

 for optimizing the weighted least squares data term.
 
\begin_inset CommandInset citation
LatexCommand cite
key "nien2015fast"

\end_inset

 used Linearized ADMM 
\begin_inset CommandInset citation
LatexCommand cite
key "parikh2013proximal"

\end_inset

 (also known as Inexact Split Uzawa 
\begin_inset CommandInset citation
LatexCommand cite
key "esser2010general"

\end_inset

) with Ordered Subset-based methods 
\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered"

\end_inset

 for optimizing the data term and FISTA 
\begin_inset CommandInset citation
LatexCommand cite
key "beck2009fast"

\end_inset

 for optimizing the prior term.
 However, none of these methods used SART as their data term solver, which
 provides superior reconstruction as we will next.
\end_layout

\begin_layout Standard
There are currently a number of open source software packages for tomography
 reconstruction.
 SNARK09 
\begin_inset CommandInset citation
LatexCommand cite
key "klukowska2013snark09"

\end_inset

 is one of the oldest.
 The Reconstruction ToolKit (RTK) 
\begin_inset CommandInset citation
LatexCommand cite
key "rit2014reconstruction"

\end_inset

 is a high performance C++ toolkit focusing on 3D cone beam reconstruction
 that is based on the image processing package Insight ToolKit (ITK).
 It includes implementations of several algorithms, including FDK, SART,
 and an ADMM TV-regularized solver with CG 
\begin_inset CommandInset citation
LatexCommand cite
key "mory2012ecg"

\end_inset

.
 The ASTRA toolbox 
\begin_inset CommandInset citation
LatexCommand cite
key "van2015astra"

\end_inset

 is a Matlab-based GPU-accelerated toolbox for tomography reconstruction.
 It includes implementations of several algorithms, including SART, SIRT,
 FBP, among others.
 We modify and extend ASTRA to implement our algorithms and generate the
 experiments in this paper.
\end_layout

\begin_layout Section
Iterative Algorithms
\begin_inset CommandInset label
LatexCommand label
name "sec:Iterative-Algorithms"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Overview
\begin_inset CommandInset label
LatexCommand label
name "sub:Overview-Iterative-Algorithms"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
protect
\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:Iterative-Algorithm"

\end_inset

Outline of Iterative Algorithms
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1]
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Require
\end_layout

\end_inset

 
\begin_inset Formula $A\in\mathbb{R}{}^{m\times n}$
\end_inset

, 
\begin_inset Formula $\alpha\in\mathbb{R}$
\end_inset

, 
\begin_inset Formula $p\in\mathbb{R}{}^{m}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 Initialize: 
\begin_inset Formula $x^{(0)}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset Formula $t=1\ldots T$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

subsets 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset


\begin_inset Formula $x^{(t+1)}=x^{(t)}+\alpha\Delta x^{(t)}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset


\begin_inset Formula $x^{(t+1)}=\mbox{clip}(x^{(t+1)})$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Return
\end_layout

\end_inset

 volume reconstruction 
\begin_inset Formula $x\in\mathbb{R}{}^{n}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The tomography problem can be simplified to solving a linear system 
\begin_inset CommandInset citation
LatexCommand cite
key "kak2001principles,herman2009fundamentals"

\end_inset

 
\begin_inset Formula 
\begin{equation}
Ax=p,\label{eq:linear-system}
\end{equation}

\end_inset

where 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is the unknown volume in vector form, 
\begin_inset Formula $A\in\mathbb{R}^{m\times n}$
\end_inset

 is the projection system matrix, and 
\begin_inset Formula $p\in\mathbb{R}^{m}$
\end_inset

 represents the measured line projections (sinogram).
 The iterative algorithms that we study in this work all have the same general
 outline in Alg.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Iterative-Algorithm"

\end_inset

, but differ in the update formula in step 4.
 The subset 
\begin_inset Formula $S$
\end_inset

 in step 3 can be only 1 projection ray as in ART i.e.
 there are 
\begin_inset Formula $m$
\end_inset

 subsets 
\begin_inset Formula $S_{i}=\{i\,|\, i=1\ldots m\}$
\end_inset

; can contain all the rays in a projection view as in SART i.e.
 there are 
\begin_inset Formula $m/s$
\end_inset

 subsets where 
\begin_inset Formula $s$
\end_inset

 is the number of projection views; or can contain the whole projection
 rays as in SIRT i.e.
 there is only one subset 
\begin_inset Formula $S=\{1,\ldots,m\}$
\end_inset

.
 The update step 
\begin_inset Formula $\Delta x^{(t)}$
\end_inset

 is typically a function of (a subset of) the forward projection error 
\begin_inset Formula $p_{S}-A_{S}x^{(t)}$
\end_inset

 that is then back projected with some normalization procedure.
 It can take the form 
\begin_inset Formula 
\[
\Delta x^{(t)}=\Phi\left(A_{S}^{T},p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

where the function 
\begin_inset Formula $\Phi(\cdot)$
\end_inset

 computes the required update, see below.
 This can be seen as an approximation to the actual gradient 
\begin_inset Formula $A^{T}(p-Ax)$
\end_inset

 of the least square objective 
\begin_inset Formula 
\[
\argmin_{x}\Vert Ax-p\Vert_{2}^{2}
\]

\end_inset

 and so these algorithms can be viewed as variations of (stochastic) gradient
 descent 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2015combining"

\end_inset

 where they differ on how they approximate the gradient.
 We also notice that the inner loop in step 3 for all these algorithms takes
 roughly the same time, since it involves one full sweep over the rows of
 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Standard
Below we will quickly review the different methods, and Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Iterative-Methods"

\end_inset

 provides a summary of their important properties.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
center
\end_layout

\begin_layout Plain Layout


\backslash
renewcommand*
\backslash
arraystretch{1.5}
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="5">
<features rotate="0" booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top">
<column alignment="center" valignment="middle" width="3text%">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Method
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Update Step
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Subset
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Solved Problem
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Converges
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ART 
\begin_inset CommandInset citation
LatexCommand cite
key "gordon1970algebraic"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{p_{i}-\sum_{k}a_{ik}x_{k}^{(t)}}{\sum_{k}a_{ik}^{2}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha A_{i}^{T}R^{-1}\left(p_{i}-A_{i}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one ray
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x^{\star}= & \argmin_{x}\Vert x\Vert_{2}^{2}\\
 & \st Ax=p
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SIRT 
\begin_inset CommandInset citation
LatexCommand cite
key "gilbert1972iterative"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{1}{\sum_{i=1}^{m}a_{ij}}\sum_{i=1}^{m}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha C^{-1}A^{T}R^{-1}\left(p-Ax^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
all rays
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{R^{-1}}^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SART 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{1}{\sum_{i\in S}a_{ij}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha C_{S}^{-1}A_{S}^{T}R^{-1}\left(p-A_{S}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one view
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x^{\star}\approx & \argmin_{x}\Vert x\Vert_{2}^{2}\\
 & \st Ax=p
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
No
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BSSART 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{1}{\sum_{i=1}^{m}a_{ij}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha C^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one view
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x^{\star}= & \argmin_{x}\Vert x\Vert_{2}^{2}\\
 & \st Ax=p
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BICAV 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2001bicav"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{1}{\sum_{i\in S}\{a_{ij}\ne0\}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}^{2}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha C_{S}^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one view
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x^{\star}= & \argmin_{x}\Vert x\Vert_{2}^{2}\\
 & \st Ax=p
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OS-SQS 
\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\frac{\alpha s}{\left(\sum_{k=1}^{m}a_{kj}\sum_{i=1}^{n}a_{ki}\right)}\sum_{i\in S}\left(p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}\right)a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha sC^{-1}A_{S}^{T}\left(p_{S}-A_{S}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one view
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x^{\star}\approx\Vert Ax-p\Vert_{2}^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
No
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CGLS 
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical,fessler1999conjugate"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x^{(t+1)}=x^{(t)}+\alpha_{t}\Phi\left(A^{T}(p-Ax^{(t)})\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
all rays
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x^{\star}=\Vert Ax-p\Vert_{2}^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
renewcommand*
\backslash
arraystretch{1}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Summary of iterative methods and their properties.
\begin_inset CommandInset label
LatexCommand label
name "tab:Iterative-Methods"

\end_inset

 The first line in the update step is voxel-based, while the second is the
 matrix formulation.
 See Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Iterative-Algorithms"

\end_inset

 for details.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
ART
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "gordon1970algebraic,gordon1971reconstruction"

\end_inset

 is the first algebraic method, and is based on Kaczmarz alternating projection
 algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "kaczmarz1937angenaherte"

\end_inset

.
 ART treats each row of 
\begin_inset Formula $A$
\end_inset

 in turn, and updates the current estimate according to 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{p_{i}-\sum_{k}a_{ik}x_{k}^{(t)}}{\sum_{k}a_{ik}^{2}}a_{ij}\mbox{ for }i=1\ldots m,
\end{eqnarray*}

\end_inset

 where 
\begin_inset Formula $x_{j}^{(t)}$
\end_inset

 is the 
\begin_inset Formula $j$
\end_inset

th voxel at time 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $a_{ij}$
\end_inset

 is the entry in the 
\begin_inset Formula $i$
\end_inset

th row and 
\begin_inset Formula $j$
\end_inset

th column of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $\alpha\in\mathbb{R}$
\end_inset

 is the relaxation parameter.
 This update is performed once each row of 
\begin_inset Formula $A$
\end_inset

, and one iteration includes a full pass over all the 
\begin_inset Formula $m$
\end_inset

 rows.
 The term 
\begin_inset Formula $\sum_{k}a_{ik}x_{k}^{(t)}$
\end_inset

 is the forward projection of the volume estimate for the 
\begin_inset Formula $i$
\end_inset

th ray (equation or row), the difference in the numerator is the projection
 error, that is then back projected by multiplying the transpose of the
 
\begin_inset Formula $i$
\end_inset

th row.
 It has been shown that ART converges to a least-norm solution to the consistent
 system of equations 
\begin_inset CommandInset citation
LatexCommand cite
key "tanabe1971projection"

\end_inset

 i.e.
 it solves 
\begin_inset Formula 
\begin{equation}
x^{\star}=\argmin_{x}\Vert x\Vert_{2}^{2}\st Ax=p.\label{eq:least-norm-problem}
\end{equation}

\end_inset

 In matrix notation, this can be also expressed as 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha A_{i}^{T}R^{-1}\left(p_{i}-A_{i}x^{(t)}\right)
\]

\end_inset

 where 
\begin_inset Formula $A_{i}\in\mathbb{R}^{n}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

th row of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $R\in\mathbb{R}^{m\times m}=\diag(r_{i})$
\end_inset

 is a diagonal matrix where 
\begin_inset Formula $r_{i}=\sum_{j}a_{ij}^{2}=\Vert A_{i}\Vert_{2}^{2}$
\end_inset

 is the squared-norm of the 
\begin_inset Formula $i$
\end_inset

th row 
\begin_inset Formula $A_{i}$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection

\series bold
SIRT
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "gilbert1972iterative"

\end_inset

 performs the updates 
\emph on
simultaneously 
\emph default
i.e.
 updates the volume once instead of updating it per each row 
\begin_inset Formula $A_{i}$
\end_inset

.
 The update equation becomes 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{1}{\sum_{i=1}^{m}a_{ij}}\sum_{i=1}^{m}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}.
\end{eqnarray*}

\end_inset

 In matrix form this becomes 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha C^{-1}A^{T}R^{-1}\left(p-Ax^{(t)}\right)
\]

\end_inset

 where 
\begin_inset Formula $C\in\mathbb{R}^{n\times n}=\diag(c_{j})$
\end_inset

 is a diagonal matrix whore 
\begin_inset Formula $c_{j}=\sum_{i}a_{ij}$
\end_inset

 is the sum of column 
\begin_inset Formula $j$
\end_inset

 of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $R=\diag(r_{i})$
\end_inset

 where 
\begin_inset Formula $r_{i}=\sum_{j}a_{ij}$
\end_inset

 is the sum of row 
\begin_inset Formula $i$
\end_inset

 of 
\begin_inset Formula $A$
\end_inset

.
 In each iteration, SIRT performs a full forward projection 
\begin_inset Formula $Ax^{(t)}$
\end_inset

, computes the residual, and then back projects it.
 The diagonal matrices 
\begin_inset Formula $R$
\end_inset

 and 
\begin_inset Formula $C$
\end_inset

 perform scaling for the relevant entries.
 It has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block,jiang2003convergence"

\end_inset

 that SIRT converges to a solution of the WLS problem 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{R^{-1}}^{2}=\min_{x}(Ax-p)^{T}R^{-1}(Ax-p)
\]

\end_inset

for 
\begin_inset Formula $0<\alpha<2$
\end_inset

.
 SIRT has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "gregor2015comparison"

\end_inset

 to be closely related, and in fact quite equivalent in terms of convergence
 properties, to the OS-SQS method.
 It has also been shown to converge best for 
\begin_inset Formula $\alpha=2-\epsilon$
\end_inset

 for a small 
\begin_inset Formula $0<\epsilon\ll1$
\end_inset

.
\end_layout

\begin_layout Subsubsection

\series bold
SART
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset

 is a tradeoff between ART and SIRT, in that it updates the volume after
 processing all the rows in a particular projection view.
 The update equation becomes 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{1}{\sum_{i\in S}a_{ij}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}
\end{eqnarray*}

\end_inset

for 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 where the summation 
\begin_inset Formula $i\in S$
\end_inset

 is across all rows (rays) in projection view 
\begin_inset Formula $S$
\end_inset

 for all views 
\begin_inset Formula $\mathcal{S}$
\end_inset

.
 This has been shown to provide faster convergence than ART and better reconstru
ction results than SIRT 
\begin_inset CommandInset citation
LatexCommand cite
key "mueller2000rapid,mueller1999fast"

\end_inset

.
 In matrix form 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha C_{S}^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

 where 
\begin_inset Formula $A_{S}\in\mathbb{R}^{s\times n}$
\end_inset

 contains the 
\begin_inset Formula $s$
\end_inset

 rows in projection 
\begin_inset Formula $S$
\end_inset

, 
\begin_inset Formula $p_{S}$
\end_inset

 contains the corresponding 
\begin_inset Formula $s$
\end_inset

 rays from the projection measurements, 
\begin_inset Formula $R$
\end_inset

 contains the row sums as in SIRT, while 
\begin_inset Formula $C_{S}=\diag(c_{j}^{S})$
\end_inset

 contains the column sums restricted to the rows in 
\begin_inset Formula $S$
\end_inset

 i.e.
 
\begin_inset Formula $c_{j}^{S}=\sum_{i\in S}a_{ij}$
\end_inset

.
 There is still no proof of convergence for SART in the literature, but
 there are proofs for variants of SART, such as BSSART and BICAV below,
 that converge to a minimum-norm solution like ART.
 This motivates us to assume that SART solves approximately the minimum-norm
 solution 
\begin_inset Formula 
\[
x^{\star}\approx\argmin_{x}\Vert x\Vert_{2}^{2}\st Ax=p.
\]

\end_inset


\end_layout

\begin_layout Subsubsection

\series bold
BSSART
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset

 is a slight simplification of SART, where the column sums in the update
 equation are done over 
\emph on
all
\emph default
 the rows of 
\begin_inset Formula $A$
\end_inset

 instead of just over the rows in the current view, which is quite similar
 to SIRT.
 The update equation becomes 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{1}{\sum_{i=1}^{m}a_{ij}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}
\end{eqnarray*}

\end_inset

 for 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 , which provides a slight speedup since the column sums are now independent
 of the iteration.
 The matrix formulation becomes 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha C^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

 where the diagonal matrices are both independent of the projection view
 
\begin_inset Formula $S$
\end_inset

 as in SIRT.
 This has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset

 to converge to the minimum norm solution 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert x\Vert_{2}^{2}\st Ax=p
\]

\end_inset

 as ART for 
\begin_inset Formula $0<\alpha<2$
\end_inset

.
\end_layout

\begin_layout Subsubsection

\series bold
BICAV
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "censor2001bicav,censor2002block"

\end_inset

 is another closely-related algorithm to SART.
 It updates the volume after each projection view according to 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{1}{c_{j}^{S}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}^{2}}a_{ij}
\end{eqnarray*}

\end_inset

for 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 where 
\begin_inset Formula $c_{j}^{S}=\sum_{i\in S}\{a_{ij}\ne0\}$
\end_inset

 and 
\begin_inset Formula $\{a_{ij}\ne0\}=1$
\end_inset

 when 
\begin_inset Formula $a_{ij}$
\end_inset

 is non-zero is 0 otherwise.
 The difference from SART is that it computes the squared norm of the rows
 of 
\begin_inset Formula $A$
\end_inset

 and counts the number of non-zero entries in the columns of 
\begin_inset Formula $A$
\end_inset

.
 The matrix formulation is 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha C_{S}^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

 where now 
\begin_inset Formula $r_{i}=\sum_{j}a_{ij}^{2}=\Vert A_{i}\Vert_{2}^{2}$
\end_inset

 and 
\begin_inset Formula $C_{S}=\diag(c_{j}^{S})$
\end_inset

.
 It is shown 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset

 that BICAV converges to the minimum-norm solution 
\begin_inset Formula 
\[
\min_{x}\Vert x\Vert^{2}\st Ax=p
\]

\end_inset

 for 
\begin_inset Formula $0<\alpha<2$
\end_inset

.
\end_layout

\begin_layout Subsubsection

\series bold
OS-SQS
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered,kim2013accelerating,kim2015combining,nien2015fast"

\end_inset

 is closely related to SART.
 It is usually derived from a majorization-minimization perspective 
\begin_inset CommandInset citation
LatexCommand cite
key "depierro1994modified,erdogan1999ordered,kim2013accelerating,kim2015combining"

\end_inset

, but with a specific choice of surrogate functions and parameters 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2013accelerating"

\end_inset

 the update equation becomes
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{s}{c_{j}}\sum_{i\in S}\left(p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}\right)a_{ij}
\end{eqnarray*}

\end_inset

for 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 where 
\begin_inset Formula $s$
\end_inset

 is the number of subsets 
\begin_inset Formula $S$
\end_inset

 in 
\begin_inset Formula $\mathcal{S}$
\end_inset

 (number of inner iterations), 
\begin_inset Formula $c_{j}=\left(\sum_{k=1}^{m}a_{kj}\sum_{i=1}^{n}a_{ki}\right)$
\end_inset

, and in general the set 
\begin_inset Formula $S$
\end_inset

 can contain more than one projection view.
 In matrix form it becomes 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha sC^{-1}A_{S}^{T}\left(p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

 where the matrix 
\begin_inset Formula $C=\diag(A^{T}A\mathbf{1}_{m})=\diag(c_{j})$
\end_inset

 where 
\begin_inset Formula $\mathbf{1}_{m}$
\end_inset

 is the vector of 
\begin_inset Formula $m$
\end_inset

 ones.
 OS-SQS is a special case of the SQS method, which processes all the rows
 of 
\begin_inset Formula $A$
\end_inset

 at once like SIRT.
 SQS has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered"

\end_inset

 to converge to a least square solution 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{2}^{2},
\]

\end_inset

 and special case of 
\emph on
relaxed
\emph default
 OS-SQS converges, where the relaxation parameter becomes iteration-dependent
 and decreases over time 
\begin_inset CommandInset citation
LatexCommand cite
key "ahn2003globally"

\end_inset

.
 However, OS-SQS with fixed 
\begin_inset Formula $\alpha$
\end_inset

 is not known to converge.
 Therefore, like SART, we assume that it solves the LS problem above approximate
ly.
 
\end_layout

\begin_layout Subsubsection

\series bold
CGLS
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical,fessler1999conjugate"

\end_inset

 is a type of Conjugate Gradient that solves the least squares normal equations
 directly.
 Like SIRT, it updates the constraint once per full sweep over the projection
 rays.
 The update equation in matrix notation is 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha_{t}\Phi(A^{T}(p-Ax^{(t)}))
\]

\end_inset

 where the update step is a function of the backprojection of the projection
 error, and the parameter 
\begin_inset Formula $\alpha_{t}$
\end_inset

 depends on the specific version of CGLS (here we use the Fletcher-Reeves
 update rule
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical"

\end_inset

).
 CGLS is proven to be convergent to the solution of the LS problem 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Section
Proximal Operators
\begin_inset CommandInset label
LatexCommand label
name "sec:Proximal-Operators"

\end_inset


\end_layout

\begin_layout Standard
Proximal algorithms are a class of optimization algorithms that are quite
 flexible and powerful 
\begin_inset CommandInset citation
LatexCommand cite
key "combettes2011proximal,boyd2011distributed,parikh2013proximal"

\end_inset

.
 They are generally used to efficiently solve non-smooth, constrained, distribut
ed, or large scale optimization problems.
 They are more modular than other optimization problems, in the sense that
 they provide a few lines of code that depend on solving smaller conventional,
 and usually simpler, optimization problems called 
\emph on
proximal operator
\emph default
.
 The proximal operator 
\begin_inset CommandInset citation
LatexCommand cite
key "bauschke2011convex,combettes2011proximal,parikh2013proximal"

\end_inset

 for a function 
\begin_inset Formula $h(\cdot)$
\end_inset

 is a generalization of projections on convex sets, and can be thought of
 intuitively as getting closer to the optimal solution while staying close
 to the current estimate.
 Formally it is defined as 
\begin_inset Formula 
\begin{equation}
\prox_{\lambda h}(u)=\argmin_{x}h(x)+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2},\label{eq:prox-operator}
\end{equation}

\end_inset

where 
\begin_inset Formula $x,u\in\mathbb{R}^{n}$
\end_inset

 and 
\begin_inset Formula $\lambda$
\end_inset

 is a regularization parameter.
 Many proximal operators of common functions are easy to compute, and often
 admit a closed form solution.
 Computing the proximal operator of a certain function opens the way to
 solving hard optimization problems involving this function and other regulariza
tion terms e.g.
 smoothing norms or sparsity inducing norms, which otherwise is not generally
 easy.
 We will derive proximal operators for SART, ART, BICAV, and OS-SQS.
\end_layout

\begin_layout Subsection
SART, ART, and BICAV
\end_layout

\begin_layout Standard
ART, SART, and BICAV (approximately) solve the least-norm problem 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert x\Vert_{2}^{2}\st Ax=p.
\]

\end_inset

 What we want is a solver for LS projection error i.e.
 
\begin_inset Formula 
\begin{equation}
\mbox{prox}_{\lambda h}(u)=\argmin_{x}\Vert Ax-p\Vert_{2}^{2}+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}.\label{eq:SART-prox-1-1}
\end{equation}

\end_inset

 This is equivalent to solving 
\begin_inset Formula 
\begin{equation}
\min_{x}2\lambda\Vert Ax-p\Vert_{2}^{2}+\Vert x-u\Vert_{2}^{2}.\label{eq:SART-prox-2}
\end{equation}

\end_inset

Now introduce new variables as follows: let 
\begin_inset Formula $y=\sqrt{2\lambda}(p-Ax)$
\end_inset

 and 
\begin_inset Formula $z=x-u$
\end_inset

.
 The problem becomes 
\begin_inset Formula 
\begin{eqnarray}
\min_{y,z} & \Vert y\Vert_{2}^{2}+\Vert z\Vert_{2}^{2}\nonumber \\
\st & y+\sqrt{2\lambda}Az=\sqrt{2\lambda}(p-Au).\label{eq:SART-prox-3}
\end{eqnarray}

\end_inset

Rewriting Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:SART-prox-3"

\end_inset

 we arrive at the system 
\begin_inset Formula 
\begin{eqnarray*}
\mbox{\ensuremath{\min}}_{y,z} & \left\Vert \left[\begin{array}{c}
y\\
z
\end{array}\right]\right\Vert _{2}^{2}\\
\mbox{subject to} & \left[\begin{array}{cc}
I & \sqrt{2\lambda}A\end{array}\right]\left[\begin{array}{c}
y\\
z
\end{array}\right]=\sqrt{2\lambda}\left(p-Au\right)
\end{eqnarray*}

\end_inset

which can be written as 
\begin_inset Formula 
\begin{eqnarray*}
\mbox{\ensuremath{\min}}_{\tilde{x}} & \left\Vert \tilde{x}\right\Vert _{2}^{2}\\
\st & \tilde{A}\tilde{x}=\tilde{p},
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $\tilde{x}\in\mathbb{R}^{m+n}$
\end_inset

, 
\begin_inset Formula $\tilde{A}\in\mathbb{R}^{m\times m+n}$
\end_inset

, and 
\begin_inset Formula $\tilde{p}\in\mathbb{R}^{m}$
\end_inset

.
 This is now a consistent under-determined linear system, and can be solved
 using either ART, SART, or BICAV.
 
\end_layout

\begin_layout Standard
Although we introduced new variables 
\begin_inset Formula $y$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 and increased the dimensionality of the problem from 
\begin_inset Formula $n$
\end_inset

 to 
\begin_inset Formula $n+m$
\end_inset

, we can solve the modified algorithm efficiently with very little computational
 overhead.
 Instead of solving explicitly for the optimal 
\begin_inset Formula $y^{\star}$
\end_inset

 and 
\begin_inset Formula $z^{\star}$
\end_inset

, we can manipulate the algorithm to solve directly for the optimal 
\begin_inset Formula $x^{\star}.$
\end_inset

 For example, for SART, the initialization and update equation for 
\begin_inset Formula $\tilde{x}$
\end_inset

 become 
\begin_inset Formula 
\begin{eqnarray}
\tilde{x}_{j}^{(0)} & = & \mathbf{0},\nonumber \\
\tilde{x}_{j}^{(t+1)} & = & \tilde{x}_{j}^{(t)}+\alpha\frac{\sum_{i\in\mathcal{S}}\frac{\tilde{p}_{i}-\sum_{k}\tilde{a}_{ik}\tilde{x}_{k}^{(t)}}{\sum_{k}\tilde{a}_{ik}}\tilde{a}_{ij}}{\sum_{i\in S}\tilde{a}_{ij}},\label{eq:SART-proximal-update-1}
\end{eqnarray}

\end_inset

which can be expanded in terms of 
\begin_inset Formula $y$
\end_inset

, 
\begin_inset Formula $z$
\end_inset

, and 
\begin_inset Formula $A$
\end_inset

 as 
\begin_inset Formula 
\begin{eqnarray*}
y^{(0)} & = & \mathbf{0}_{m}\\
z^{(0)} & = & \mathbf{0}_{n}\\
y_{j}^{(t+1)} & = & y_{j}^{(t)}+\frac{\alpha\sum_{i\in\mathcal{S}}\frac{\tilde{p}_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}z_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\delta_{ij}}{1},\\
z_{j}^{(t+1)} & = & z_{j}^{(t)}+\alpha\frac{\sum_{i\in\mathcal{S}}\frac{\tilde{p}_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}z_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\sqrt{2\lambda}a_{ij}}{\sqrt{2\lambda}\sum_{i\in S}a_{ij}},
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $\delta_{ij}=1$
\end_inset

 when 
\begin_inset Formula $i=j$
\end_inset

 and 0 otherwise.
 Using the fact that 
\begin_inset Formula $z=x-u$
\end_inset

 and 
\begin_inset Formula $\tilde{p}_{i}=\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}u_{k}$
\end_inset

 and simplifying we arrive at 
\begin_inset Formula 
\begin{eqnarray*}
y^{(0)} & = & \mathbf{0}_{m}\\
x^{(0)} & = & u\\
y_{j}^{(t+1)} & = & y_{j}^{(t)}+\alpha\sum_{i\in S}\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\delta_{ij},\\
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{\sum_{i\in S}\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\sqrt{2\lambda}a_{ij}}{\sqrt{2\lambda}\sum_{i\in S}a_{ij}}.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Following the same line of reasoning, we can arrive at similar update formulas
 for both ART and BICAV.
 The steps are summarized in Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Prox-Operators"

\end_inset

.
\end_layout

\begin_layout Subsection
OS-SQS
\end_layout

\begin_layout Standard
We want to express the proximal operator problem in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:SART-prox-1-1"

\end_inset

 in the form of a the LS problem that can be solved (approximately) by OS-SQS:
 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{2}^{2}.
\]

\end_inset

 Rewrite in the form 
\begin_inset Formula 
\begin{equation}
\argmin_{x}2\lambda\Vert Ax-p\Vert_{2}^{2}+\Vert x-u\Vert_{2}^{2}.\label{eq:SART-prox-2-1}
\end{equation}

\end_inset

which is equivalent to 
\begin_inset Formula 
\begin{align*}
 & \argmin_{x}\left\Vert \left[\begin{array}{c}
\sqrt{2\lambda}A\\
I
\end{array}\right]x-\left[\begin{array}{c}
\sqrt{2\lambda}p\\
u
\end{array}\right]\right\Vert _{2}^{2}\\
 & \iff\argmin_{x}\left\Vert \tilde{A}x-\tilde{p}\right\Vert _{2}^{2}
\end{align*}

\end_inset

 where 
\begin_inset Formula 
\begin{eqnarray*}
\tilde{A} & = & \left[\begin{array}{c}
\sqrt{2\lambda}A\\
I
\end{array}\right]\in\mathbb{R}^{m+n\times n}\\
\tilde{p} & = & \left[\begin{array}{c}
\sqrt{2\lambda}p\\
u
\end{array}\right]\in\mathbb{R}^{m+n}.
\end{eqnarray*}

\end_inset

The weighting matrix 
\begin_inset Formula $\tilde{C}\in\mathbb{R}^{n\times n}$
\end_inset

 now becomes now becomes 
\begin_inset Formula 
\begin{eqnarray*}
\tilde{C} & = & \mbox{diag}(\tilde{A}^{T}\tilde{A}\mathbf{1})\\
 & = & \mbox{diag}\left((2\lambda A^{T}A+I)\mathbf{1}\right)\\
 & = & \mbox{diag}\left(2\lambda A^{T}A\mathbf{1}+\mathbf{1}\right)
\end{eqnarray*}

\end_inset

 and its diagonal entries are 
\begin_inset Formula 
\[
\tilde{c}_{j}=2\lambda c_{j}+1
\]

\end_inset


\end_layout

\begin_layout Standard
Write the matrix update equation in terms of 
\begin_inset Formula $\tilde{A}$
\end_inset

 and 
\begin_inset Formula $\tilde{p}$
\end_inset

 as 
\begin_inset Formula 
\begin{align*}
x^{(t+1)} & =x^{(t)}+\alpha s\tilde{C}^{-1}\tilde{A}_{S}^{T}\left(\tilde{p}_{S}-\tilde{A}_{S}x^{(t)}\right)\\
 & =x^{(t)}+\alpha s\tilde{C}^{-1}\left[\begin{smallmatrix}\sqrt{2\lambda}A_{S}^{T} & I\end{smallmatrix}\right]\left[\begin{smallmatrix}\sqrt{2\lambda}(p_{S}-A_{S}x^{(t)})\\
u-x^{(t)}
\end{smallmatrix}\right]\\
 & =x^{(t)}+\alpha s\tilde{C}^{-1}{\scriptstyle \left(2\lambda A_{S}^{T}(p_{S}-A_{S}x^{(t)})+(u-x^{(t)})\right)}.
\end{align*}

\end_inset

In component form 
\begin_inset Formula 
\begin{align*}
x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{s}{\tilde{c}_{j}}{\scriptstyle \left(2\lambda\sum_{i\in S}(p_{j}-\sum_{k}a_{ik}x_{k}^{(t)})a_{ij}+u_{j}-x_{j}^{(t)}\right)}.
\end{align*}

\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Write the matrix update equation in terms of 
\begin_inset Formula $\tilde{A}$
\end_inset

 and 
\begin_inset Formula $\tilde{p}$
\end_inset

 as 
\begin_inset Formula 
\begin{align*}
x^{(t+1)} & =x^{(t)}+\alpha s\tilde{C}^{-1}\tilde{A}_{S}^{T}\left(\tilde{p}_{S}-\tilde{A}_{S}x^{(t)}\right)\\
 & =x^{(t)}+\alpha s\tilde{C}^{-1}\left[\begin{smallmatrix}\sqrt{2\lambda}A_{S}^{T} & I_{S}\end{smallmatrix}\right]\left[\begin{smallmatrix}\sqrt{2\lambda}(p_{S}-A_{S}x^{(t)})\\
u_{S}-x_{S}^{(t)}
\end{smallmatrix}\right]\\
 & =x^{(t)}+\alpha s\tilde{C}^{-1}{\scriptstyle \left(2\lambda A_{S}^{T}(p_{S}-A_{S}x^{(t)})+I_{S}(u_{S}-x_{S}^{(t)})\right)}
\end{align*}

\end_inset

where 
\begin_inset Formula $u_{S}$
\end_inset

 contains a subset of entries of 
\begin_inset Formula $u$
\end_inset

, and similarly for 
\begin_inset Formula $x_{S}^{(t)}$
\end_inset

.
 In component form 
\begin_inset Formula 
\begin{align*}
x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{s}{\tilde{c}_{j}}{\scriptstyle \left(2\lambda\sum_{i\in S}(p_{j}-\sum_{k}a_{ik}x_{k}^{(t)})a_{ij}+(u_{j}-x_{j}^{(t)})\delta_{jS}\right)}
\end{align*}

\end_inset

 where 
\begin_inset Formula $\delta_{jS}=1$
\end_inset

 if 
\begin_inset Formula $j\in S$
\end_inset

 and 0 otherwise.
 Note that we only include a subset from the second term 
\begin_inset Formula $u-x^{(t)}$
\end_inset

 per each inner iteration (each subset 
\begin_inset Formula $S$
\end_inset

).
\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
center
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="5" columns="2">
<features rotate="0" booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Method
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Update Step
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ART 
\begin_inset CommandInset citation
LatexCommand cite
key "gordon1970algebraic"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}y_{i}^{(t+1)} & =y_{i}^{(t)}+\alpha\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{2\lambda\sum_{k}a_{ik}^{2}+1}\mbox{ for }i\in S\\
x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{2\lambda\sum_{k}a_{ik}^{2}+1}\sqrt{2\lambda}a_{ij}\mbox{ for }j=1\ldots n
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SART 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}y_{i}^{(t+1)} & =y_{i}^{(t)}+\alpha\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\mbox{ for }i\in S\\
x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{\sum_{i\in S}\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\sqrt{2\lambda}a_{ij}}{\sqrt{2\lambda}\sum_{i\in S}a_{ij}}\mbox{ for }j=1\ldots n
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BICAV 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2001bicav"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}y_{i}^{(t+1)} & =y_{i}^{(t)}+\alpha\frac{\sqrt{2\lambda}p_{j}-\sqrt{2\lambda}\sum_{k}a_{jk}x_{k}^{(t)}-y_{j}^{(t)}}{2\lambda\sum_{k}a_{jk}^{2}+1}\mbox{ for }i\in S\\
x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{\sum_{i\in S}\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{2\lambda\sum_{k}a_{ik}^{2}+1}\sqrt{2\lambda}a_{ij}}{\sum_{i\in S}\{a_{ij}\ne0\}}\mbox{ for }j=1\ldots n
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OS-SQS 
\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{s}{2\lambda c_{j}+1}\left(2\lambda\sum_{i\in S}(p_{j}-\sum_{k}a_{ik}x_{k}^{(t)})a_{ij}+u_{j}-x_{j}^{(t)}\right)\mbox{ for }j=1\ldots n\end{aligned}
$
\end_inset


\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{s}{2\lambda c_{j}+1}\left(2\lambda\sum_{i\in S}(p_{j}-\sum_{k}a_{ik}x_{k}^{(t)})a_{ij}+(u_{j}-x_{j}^{(t)})\delta_{jS}\right)\mbox{ for }j=1\ldots n\end{aligned}
$
\end_inset


\end_layout

\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Summary of the proximal operators update steps.
\begin_inset CommandInset label
LatexCommand label
name "tab:Prox-Operators"

\end_inset

 See Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Proximal-Operators"

\end_inset

 for details.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Proximal Framework
\begin_inset CommandInset label
LatexCommand label
name "sec:Proximal-Framework"

\end_inset


\end_layout

\begin_layout Subsection
Proximal Algorithm
\end_layout

\begin_layout Standard
The overall problem we are interested in solving is a regularized data fitting
 problem.
 In particular, the problem we are interested in solving is 
\begin_inset Formula 
\begin{equation}
\argmin_{x}f(x)+g(Kx),\label{eq:full-problem}
\end{equation}

\end_inset

where 
\begin_inset Formula $f(\cdot)$
\end_inset

 is a data fitting term that measures how much the solution fits the data
 and that depends on the measurement noise model assumed, 
\begin_inset Formula $K\in\mathbb{R}^{d\times n}$
\end_inset

 is a matrix, and 
\begin_inset Formula $g(\cdot)$
\end_inset

 is a regularization term that imposes constraints on acceptable solutions.
 We will use the linearized ADMM method 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2011distributed,parikh2013proximal"

\end_inset

 for solving this problem for different data terms and different regularizers.
 It rewrites Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:full-problem"

\end_inset

 into the equivalent form 
\begin_inset Formula 
\begin{align*}
\argmin_{x,z} & f(x)+g(z)\\
\st & Kx=z
\end{align*}

\end_inset

 and iterates the steps in Alg.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:LADMM-algorithm"

\end_inset

.
 This framework is very flexible, and we will show how to solve for different
 data terms and different regularizers.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
protect
\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:LADMM-algorithm"

\end_inset

Linearized ADMM
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1]
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Require
\end_layout

\end_inset

 
\begin_inset Formula $K\in\mathbb{R}{}^{d\times n}$
\end_inset

, 
\begin_inset Formula $\rho,\mu\in\mathbb{R}$
\end_inset

 such that 
\begin_inset Formula $\mu\rho\Vert K\Vert^{2}<1$
\end_inset

, initial values 
\begin_inset Formula $x^{(0)}\in\mathbb{R}^{n}$
\end_inset

 and 
\begin_inset Formula $z^{(0)}\in\mathbb{R}^{d}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 Initialize 
\begin_inset Formula $u^{(0)}=\mathbf{0}_{d}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset Formula $t=1\ldots T$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 
\begin_inset Formula $x^{(t+1)}=\mbox{prox}_{\mu f}\left(x^{(t)}-\rho\mu K^{T}(Kx^{(t)}-z^{(t)}+u^{(t)})\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 
\begin_inset Formula $z^{(t+1)}=\mbox{prox}_{\rho^{-1}g}\left(Kx^{(t+1)}+u^{(t)}\right)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 
\begin_inset Formula $u^{(t+1)}=u^{(t)}+Kx^{(t+1)}-z^{(t+1)}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Return
\end_layout

\end_inset

 
\begin_inset Formula $x^{(T)}=\argmin_{x}f(x)+g(Kx)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Data Terms
\end_layout

\begin_layout Standard
We will consider the following data fidelity terms, which correspond to
 specific noise models:
\end_layout

\begin_layout Subsubsection
Gaussian Noise
\end_layout

\begin_layout Standard
Assume the measurements 
\begin_inset Formula $p_{i}\forall i=1,\ldots m$
\end_inset

 follow the model
\begin_inset Formula 
\begin{equation}
p_{i}=a_{i}^{T}x+\varepsilon_{i}\label{eq:Gaussian-Noise-Model}
\end{equation}

\end_inset

where 
\begin_inset Formula $\varepsilon\sim\mathbb{N}(0,1)$
\end_inset

.
 The projection data log-likelihood is
\begin_inset Formula 
\begin{equation}
\mathcal{L}_{\text{G}}(p)\propto-\sum_{i}\left(p_{i}-a_{i}^{T}x\right)^{2}\label{eq:Gaussian-Log-Likelihood}
\end{equation}

\end_inset

and maximizing 
\begin_inset Formula $\mathcal{L}_{\text{G}}(p)$
\end_inset

 is equivalent to minimizing the LS 
\begin_inset Formula $\ell_{2}$
\end_inset

 norm data term
\begin_inset Formula 
\begin{equation}
f_{\text{G}}(x)=\Vert Ax-p\Vert_{2}^{2}=\sum_{i=1}^{m}(A_{i}^{T}x-p_{i})^{2}.\label{eq:gaussian-data-term}
\end{equation}

\end_inset

We can solve proximal operator 
\begin_inset Formula $\prox_{\lambda f_{\text{G}}}(\cdot)$
\end_inset

 directly using any of the algorithms from Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Prox-Operators"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Poisson Noise
\end_layout

\begin_layout Standard
Assuming an 
\emph on
approximated
\emph default
 Poisson noise model leads to a WLS data term, where the weights are proportiona
l to the detector measurements 
\begin_inset CommandInset citation
LatexCommand cite
key "clinthorne1993preconditioning,depierro1994modified,elbakri2002statistical,thibault2007three"

\end_inset

.
 Indeed, the actual measurements produced by the X-ray CT scanner represent
 X-ray photon energy reaching the detector as compared to the energy leaving
 the X-ray gun.
 These are related to each other and to the linear attenuation coefficient
 according to Beer-Lambert law 
\begin_inset CommandInset citation
LatexCommand cite
key "hsieh2009computed"

\end_inset

: 
\begin_inset Formula 
\[
I_{t}=I_{o}e^{-\int\mu(l)dl}
\]

\end_inset

where 
\begin_inset Formula $I_{t}$
\end_inset

 is the transmitted intensity as measured by the detector, 
\begin_inset Formula $I_{o}$
\end_inset

 is the emitted intensity from the source, 
\begin_inset Formula $\mu(l)$
\end_inset

 is the linear attenuation coefficient of the material as a function of
 length 
\begin_inset Formula $l$
\end_inset

.
 The exponent represents the line integrals (projection data) we are dealing
 with.
 In particular, assuming that the X-ray photons are monochromatic (have
 only one single energy) i.e.
 ignoring 
\emph on
beam hardening
\emph default
, the projection line integral data at detector 
\begin_inset Formula $i$
\end_inset

 is obtained from the physical measurements as 
\begin_inset Formula 
\begin{equation}
p_{i}=-\ln\frac{I_{t}^{i}}{I_{o}^{i}}\label{eq:p_i}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
where 
\begin_inset Formula $I_{t}^{i}$
\end_inset

 is the intensity measured by detector 
\begin_inset Formula $i$
\end_inset

 and 
\begin_inset Formula $I_{o}^{i}$
\end_inset

 is the emitted intensity.
 The detector measurements are stochastic in nature, and assuming a Poisson
 distribution with mean 
\begin_inset Formula $I_{o}^{i}\exp(-p_{i})$
\end_inset

 we get 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
A variable 
\begin_inset Formula $x$
\end_inset

 follows a Poisson distribution with mean 
\begin_inset Formula $\lambda$
\end_inset

 if 
\begin_inset Formula 
\[
x\sim\mbox{Poisson}(\lambda)\equiv P(x=X)=\frac{e^{-\lambda}\lambda^{x}}{x!}.
\]

\end_inset


\end_layout

\end_inset

 
\begin_inset Formula 
\[
I_{t}^{i}\sim\mathbb{P}(I_{o}^{i}e^{-p_{i}})\approx\mathbb{P}(I_{o}^{i}e^{-A_{i}^{T}x}).
\]

\end_inset


\end_layout

\begin_layout Standard
Using the ML approach, we maximize the log-likelihood of the measured data:
 
\begin_inset Formula 
\begin{equation}
\mathcal{L}_{P}(x)=\sum_{i}I_{t}^{i}\ln\left(I_{o}^{i}e^{-A_{i}^{T}x}\right)-I_{o}^{i}e^{-A_{i}^{T}x}=\sum_{i}\phi_{i}\left(A_{i}^{T}x\right)\label{eq:Poisson-log-likelihood-full}
\end{equation}

\end_inset

 where 
\begin_inset Formula 
\[
\phi_{i}(q)=I_{t}^{i}\ln\left(I_{o}^{i}e^{-q}\right)-I_{o}^{i}e^{-q}.
\]

\end_inset


\end_layout

\begin_layout Standard
Applying a second-order Taylor's expansion for 
\begin_inset Formula $\phi_{i}(q)$
\end_inset

 around an estimate of the 
\begin_inset Formula $i$
\end_inset

th line integral 
\begin_inset Formula $p_{i}$
\end_inset

 from Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:p_i"

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "elbakri2002statistical"

\end_inset

: 
\begin_inset Formula 
\begin{align*}
\phi_{i}(q) & \approx\phi_{i}(p_{i})+\frac{d\phi_{i}}{dq}(p_{i})(q-p_{i})+\frac{1}{2}\frac{d^{2}\phi_{i}}{dq^{2}}(p_{i})(q-p_{i})^{2}\\
 & =(I_{t}^{i}\ln I_{t}^{i}-I_{t}^{i})-\frac{I_{t}^{i}}{2}(q-p_{i})^{2}
\end{align*}

\end_inset

The first term is independent of 
\begin_inset Formula $q$
\end_inset

 and can be dropped (since we are interested in minimizing 
\begin_inset Formula $\mathcal{L}_{P}(x)$
\end_inset

).
 Substituting in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Poisson-log-likelihood-full"

\end_inset

, we end up with the approximated log-likelihood 
\begin_inset Formula 
\begin{equation}
\mathcal{L}_{\text{G}}(x)\approx-\sum_{i}\frac{I_{t}^{i}}{2}\left(A_{i}^{T}x-p_{i}\right)^{2}=-\sum w_{i}\left(A_{i}^{T}x-p_{i}\right){}^{2}\label{eq:Poisson-log-likelihood-approx}
\end{equation}

\end_inset

 where 
\begin_inset Formula $w_{i}$
\end_inset

 is the weight for projection measurement 
\begin_inset Formula $i$
\end_inset

 and is proportional to the measurement of the incident intensity on detector
 
\begin_inset Formula $i$
\end_inset

 i.e.
\begin_inset Formula 
\[
w_{i}\propto I_{t}^{i}.
\]

\end_inset

Maximizing the likelihood is equivalent to minimizing the WLS data term
 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
f_{\text{P}}(x)=\Vert Ax-p\Vert_{W}^{2}=\sum_{i=1}^{m}w_{i}(a_{i}^{T}x-p_{i})^{2}\label{eq:Poisson-data-term}
\end{equation}

\end_inset

 where 
\begin_inset Formula $\Vert x\Vert_{W}=x^{T}Wx$
\end_inset

 and 
\begin_inset Formula $W=\diag(w_{i})\in\mathbb{R}^{m\times m}$
\end_inset

 is a diagonal matrix containing weights for each measurement.
 
\end_layout

\begin_layout Standard
We can solve the proximal operator 
\begin_inset Formula 
\begin{equation}
\prox_{\lambda f_{\text{P}}}(u)=\min_{x}\Vert Ax-p\Vert_{W}^{2}+\frac{1}{2\lambda}\Vert x-u\Vert^{2}.\label{eq:Poisson-data-term-proximal-operator-initial}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
as follows.
 Define 
\begin_inset Formula $\tilde{p}\in\mathbb{R}^{m}$
\end_inset

 and 
\begin_inset Formula $\tilde{A}\in\mathbb{R}^{m\times n}$
\end_inset

 as 
\begin_inset Formula 
\begin{eqnarray*}
\tilde{p} & = & W^{\frac{1}{2}}p\\
\tilde{A} & = & W^{\frac{1}{2}}A
\end{eqnarray*}

\end_inset

 where 
\begin_inset Formula 
\[
W^{\frac{1}{2}}=\diag\left(\sqrt{w_{i}}\right).
\]

\end_inset

We now get 
\begin_inset Formula 
\begin{eqnarray*}
\Vert\tilde{A}x-\tilde{p}\Vert_{2}^{2} & = & (\tilde{A}x-\tilde{p})^{T}(\tilde{A}x-\tilde{p})\\
 & = & \left(W^{\frac{1}{2}}(Ax-p)\right)^{T}\left(W^{\frac{1}{2}}(Ax-p)\right)\\
 & = & (Ax-p)^{T}W^{\frac{1}{2}}W^{\frac{1}{2}}(Ax-p)\\
 & = & \Vert Ax-p\Vert_{W}^{2}.
\end{eqnarray*}

\end_inset

 Now this is in the form that can be solved with the algorithms in Table
 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Prox-Operators"

\end_inset

 
\begin_inset Formula 
\[
\prox_{\lambda f_{\text{P}}}(u)=\min_{x}\Vert\tilde{A}x-\tilde{p}\Vert^{2}+\frac{1}{2\lambda}\Vert x-u\Vert^{2}.
\]

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Laplace Noise
\end_layout

\begin_layout Plain Layout
The 
\begin_inset Formula $\ell_{1}$
\end_inset

 data term minimizes the 
\begin_inset Formula $\ell_{1}$
\end_inset

 norm of the errors.
 This is considered as a robust estimator, since it is less affected by
 outliers 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2004convex,sidky2012convex"

\end_inset

.
 It can also be considered a maximum likelihood estimation when the measurement
 noise 
\begin_inset Formula $\varepsilon_{i}$
\end_inset

 in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:Noise-Model"

\end_inset

 follows a Laplace distribution 
\begin_inset Formula $\varepsilon_{i}\sim\mbox{Laplace}(0,1)$
\end_inset

 (i.e.
 has a pdf of the form 
\begin_inset Formula $h(\varepsilon_{i})=\exp\left(-|\varepsilon_{i}|\right)$
\end_inset

) in which case the log-likelihood becomes 
\begin_inset Formula 
\begin{equation}
\mathcal{L}_{1}(x)=-\sum_{i=1}^{m}\vert a_{i}^{T}x-p_{i}\vert.\label{eq:L1-Log-Likelihood}
\end{equation}

\end_inset


\end_layout

\begin_layout Plain Layout
To use it we need to solve its proximal operator 
\begin_inset Formula 
\begin{equation}
\prox_{\lambda f_{1}}(u)=\argmin_{x}\Vert Ax-p\Vert_{1}+\frac{1}{2\lambda}\Vert x-u\Vert^{2}.\label{eq:L1-data-term-proximal-operator}
\end{equation}

\end_inset

We will use ADMM and variable splitting methods 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2011distributed,parikh2013proximal"

\end_inset

.
 
\end_layout

\begin_layout Plain Layout
Define 
\begin_inset Formula $z\in\mathbb{R}^{m}$
\end_inset

.
 The problem in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:L1-data-term-proximal-operator"

\end_inset

 is equivalent to 
\begin_inset Formula 
\begin{eqnarray*}
\min_{x} & \Vert z-p\Vert_{1}+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}\\
\mbox{s.t.} & Ax=z.
\end{eqnarray*}

\end_inset

Form the augmented 
\emph on
scaled 
\emph default
Lagrangian 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2011distributed,parikh2013proximal"

\end_inset

 
\begin_inset Formula 
\[
\mathcal{L}_{\rho}(x,z,y)=\Vert z-p\Vert_{1}+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}+\frac{\rho}{2}\Vert Ax-z+y\Vert_{2}^{2}
\]

\end_inset

where 
\begin_inset Formula $y\in\mathbb{R}^{m}$
\end_inset

 is the dual variable.
 Now this can be minimized ADMM by iterating minimizations w.r.t.
 
\begin_inset Formula $x$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 and updating the dual variable 
\begin_inset Formula $y$
\end_inset

:
\end_layout

\begin_layout Itemize
\begin_inset Formula $x$
\end_inset

 step: is equivalent to 
\begin_inset Formula 
\begin{align*}
x^{(t+1)} & =\argmin_{x}\frac{\rho}{2}\Vert Ax-z^{(t)}+y^{(t)}\Vert_{2}^{2}+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}\\
 & =\argmin_{x}\Vert\tilde{\rho}Ax-\tilde{\rho}(z^{(t)}-y^{(t)})\Vert_{2}^{2}+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}
\end{align*}

\end_inset

where 
\begin_inset Formula $\tilde{\rho}=\sqrt{\rho/2}$
\end_inset

, and is equivalent to the proximal operator of the 
\begin_inset Formula $\ell_{2}$
\end_inset

 data term 
\begin_inset Formula $f_{2}$
\end_inset

 in Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:L2-data-term-prox"

\end_inset

 with system matrix 
\begin_inset Formula $\tilde{\rho}A$
\end_inset

 and projection measurements 
\begin_inset Formula $\tilde{\rho}(z^{(t)}-y^{(t)})$
\end_inset

.
\end_layout

\begin_layout Itemize
\begin_inset Formula $z$
\end_inset

 step: is equivalent to
\begin_inset Formula 
\begin{eqnarray*}
z^{(t+1)} & = & \argmin_{z}\Vert z-p\Vert_{1}+\frac{\rho}{2}\Vert Ax^{(t+1)}-z+y^{(t)}\Vert_{2}^{2}\\
 & = & p+\argmin_{w=z-p}\Vert w\Vert_{1}+\frac{\rho}{2}\Vert Ax^{(t+1)}+y^{(t)}-p-w\Vert_{2}^{2}\\
 & = & p+\prox_{\rho^{-1}\ell_{1}}(Ax^{(t+1)}+y^{(t)}-p)
\end{eqnarray*}

\end_inset

 where we changed variables 
\begin_inset Formula $w=z-p$
\end_inset

.
 The last term is the proximal operator of the 
\begin_inset Formula $\ell_{1}$
\end_inset

 norm, which is the component-wise soft thresholding function 
\begin_inset Formula 
\begin{equation}
\prox_{\mu\ell_{1}}(u_{i})=S_{\mu}(u_{i})=\mbox{sign}(u_{i})\max\left(0,|u_{i}|-\mu\right)\label{eq:soft-thresholding}
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
\begin_inset Formula $y$
\end_inset

 step: 
\begin_inset Formula 
\[
y^{(t+1)}=y^{(t)}+Ax^{(t+1)}-z^{(t+1)}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
The steps are summarized in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:L1-SART-Proximal-Operator-ADMM"

\end_inset

.
\end_layout

\begin_layout Plain Layout
\begin_inset Float algorithm
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:L1-SART-Proximal-Operator-ADMM"

\end_inset


\begin_inset Formula $\ell_{1}$
\end_inset

 Data Term Proximal Operator
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1]
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Require
\end_layout

\end_inset

 
\begin_inset Formula $A\in\mathbb{R}{}^{m\times n}$
\end_inset

, 
\begin_inset Formula $u\in\mathbb{R}{}^{n}$
\end_inset

, 
\begin_inset Formula $\lambda\in\mathbb{R}$
\end_inset

, 
\begin_inset Formula $\alpha\in\mathbb{R}$
\end_inset

, 
\begin_inset Formula $p\in\mathbb{R}{}^{m}$
\end_inset

, 
\begin_inset Formula $\rho\in\mathbb{R}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 Initialize 
\begin_inset Formula 
\begin{align*}
z^{(0)}=y^{(0)}=0.
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll {
\end_layout

\end_inset


\begin_inset Formula $t=1\ldots T$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Update 
\begin_inset Formula $x$
\end_inset

: 
\begin_inset Formula 
\[
x^{(t+1)}=\argmin_{x}\left\Vert \tilde{\rho}Ax-\tilde{\rho}(z^{(t)}-y^{(t)})\right\Vert _{2}^{2}+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}
\]

\end_inset

where 
\begin_inset Formula $\tilde{\rho}=\sqrt{\rho/2}$
\end_inset

 by running Algoritm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:SART-Proximal-Operator"

\end_inset

 with system matrix 
\begin_inset Formula $\tilde{\rho}A$
\end_inset

 and input projections 
\begin_inset Formula $\tilde{\rho}(z^{(t)}-y^{(t)})$
\end_inset

 and parameters 
\begin_inset Formula $\lambda$
\end_inset

 and 
\begin_inset Formula $\alpha$
\end_inset

.
\end_layout

\begin_layout Itemize
Update 
\begin_inset Formula $z$
\end_inset

 
\begin_inset Formula 
\[
z^{(t+1)}=p+S_{\rho^{-1}}\left(Ax^{(t+1)}+y^{(t)}-p\right)
\]

\end_inset

 from Equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:soft-thresholding"

\end_inset

.
\end_layout

\begin_layout Itemize
Update 
\begin_inset Formula $y$
\end_inset

 
\begin_inset Formula 
\[
y^{(t+1)}=y^{(t)}+Ax^{(t+1)}-z^{(t+1)}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Return
\end_layout

\end_inset

 volume reconstruction 
\begin_inset Formula $x^{\star}\in\mathbb{R}{}^{n}=\argmin_{x}\Vert Ax-p\Vert_{1}+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}$
\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula $\ell_{1}$
\end_inset

 norm (the sum of the absolute errors): 
\begin_inset Formula 
\begin{equation}
f_{1}(x)=\Vert Ax-p\Vert_{1}=\sum_{i=1}^{m}\vert a_{i}^{T}x-p_{i}\vert.\label{eq:L1-data-term}
\end{equation}

\end_inset

It is a robust data term that is less sensitive to outliers and useful in
 the presence of salt-and-pepper or shot noise 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2012convex"

\end_inset

.
\end_layout

\begin_layout Plain Layout
For example, in our case, 
\begin_inset Formula 
\[
f(x)=\Vert Ax-p\Vert_{2}^{2}
\]

\end_inset

which is a measure of how well the reconstruction fits the given projection
 images.
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Regularizers
\end_layout

\begin_layout Standard
The regularizers impose constraints on the reconstruction volume.
 We will consider three state of the art regularizers:
\end_layout

\begin_layout Subsubsection
Isotropic Total Variation (ITV)
\end_layout

\begin_layout Standard
It is the sum of the gradient magnitude at each voxel 
\begin_inset CommandInset citation
LatexCommand cite
key "rudin1992nonlinear,sidky2012convex,chambolle2011first"

\end_inset

 i.e.
 
\begin_inset Formula 
\begin{equation}
h_{\text{ITV}}(x)=\sigma\Vert x\Vert_{\text{TV}}=\sigma\sum_{i}\Vert\nabla x_{i}\Vert_{2}\label{eq:h-ITV}
\end{equation}

\end_inset

 where 
\begin_inset Formula $\nabla x_{i}=\left[\begin{smallmatrix}\nabla x_{i}^{1} & \nabla x_{i}^{2}\end{smallmatrix}\right]^{T}$
\end_inset

 is the discrete gradient at voxel 
\begin_inset Formula $i$
\end_inset

 containing the horizontal forward different 
\begin_inset Formula $\nabla x_{i}^{1}$
\end_inset

 and the vertical forward difference 
\begin_inset Formula $\nabla x_{i}^{2}$
\end_inset

.
 It can be represented in the form of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:full-problem"

\end_inset

 
\begin_inset Formula 
\[
h_{\text{ITV}}(x)=g_{\text{ITV}}(Kx)
\]

\end_inset

by defining the matrix 
\begin_inset Formula $K=D\in\mathbb{R}^{2n\times n}$
\end_inset

 to be the forward difference matrix that produces the discrete gradient
 
\begin_inset Formula $\nabla x\in\mathbb{R}^{2n}$
\end_inset

: 
\begin_inset Formula 
\[
\nabla x=\begin{bmatrix}\nabla x_{i}\\
\vdots\\
\nabla x_{n}
\end{bmatrix}=Dx
\]

\end_inset

 and defining for 
\begin_inset Formula $u\in\mathbb{R}^{2n}=\begin{bmatrix}u_{1}^{T} & \cdots & u_{n}^{T}\end{bmatrix}^{T}$
\end_inset

 
\begin_inset Formula 
\[
g_{\text{ITV}}(u)=\sigma\sum_{i}\Vert u_{i}\Vert_{2}
\]

\end_inset

 The proximal operator 
\begin_inset Formula $\prox_{\lambda g_{\text{ITV}}}(u)$
\end_inset

 is 
\begin_inset CommandInset citation
LatexCommand cite
key "esser2010general,chambolle2011first"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\prox_{\lambda g_{\text{ITV}}}(u_{i})=u-\frac{\lambda\sigma u_{i}}{\max(\lambda\sigma,\Vert u_{i}\Vert_{2})}\label{eq:ITV-prox}
\end{equation}

\end_inset

 where 
\begin_inset Formula $u_{i}\in\mathbb{R}^{2}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

th component of 
\begin_inset Formula $u$
\end_inset

.
 Intuitively it projects back the vector 
\begin_inset Formula $u_{i}$
\end_inset

 to be on the Euclidean ball of radius 
\begin_inset Formula $\sigma$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Anisotropic Total Variation (ATV)
\end_layout

\begin_layout Standard
It is a simplification of ITV 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2008image,beck2009bfast,chambolle2010introduction,nien2015fast"

\end_inset

, and is defined as 
\begin_inset Formula 
\begin{equation}
h_{\text{ATV}}(x)=\sigma\Vert\nabla x\Vert_{1}\label{eq:h-ATV}
\end{equation}

\end_inset

 which is the 
\begin_inset Formula $\ell_{1}$
\end_inset

 norm of the gradient 
\begin_inset Formula $\nabla x$
\end_inset

 of the volume.
 This can be written in the form 
\begin_inset Formula 
\[
h_{\text{ATV}}(x)=g_{\text{ATV}}(Kx)
\]

\end_inset

 by defining 
\begin_inset Formula $K=D$
\end_inset

 as in the ITV case and defining for 
\begin_inset Formula $u\in\mathbb{R}^{2n}$
\end_inset

 
\begin_inset Formula 
\[
g_{\text{ATV}}(u)=\sigma\Vert u\Vert_{1}=\sigma\sum_{i}\Vert u_{i}\Vert_{1}.
\]

\end_inset

The proximal operator 
\begin_inset Formula $\prox_{\lambda g_{\text{ATV}}}(u)$
\end_inset

 is 
\begin_inset CommandInset citation
LatexCommand cite
key "esser2010general,chambolle2011first"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\prox_{\lambda g_{\text{ITV}}}(u_{i})=\sign(u_{i})\odot\max(0,\vert u_{i}\vert-\sigma)\label{eq:ATV-prox}
\end{equation}

\end_inset

 which is the soft thresholding function 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2012convex"

\end_inset

, where the max and product are component-wise operations.
\end_layout

\begin_layout Subsubsection
Sum of Absolute Differences (SAD)
\end_layout

\begin_layout Standard
It is an extension to the ATV by adding more forward differences around
 each voxel 
\begin_inset CommandInset citation
LatexCommand cite
key "gregson2012stochastic"

\end_inset

.
 In particular, it sums the differences of the voxels in the 
\begin_inset Formula $3\times3$
\end_inset

 neighborhood around each voxel 
\begin_inset Formula 
\begin{equation}
h_{\text{SAD}}(x)=\sigma\sum_{i}\sum_{k\in\mathcal{N}(i)}\vert x_{i}-x_{k}\vert\label{eq:h-SAD}
\end{equation}

\end_inset

where 
\begin_inset Formula $\mathcal{\mathcal{N}}(i)$
\end_inset

 contains the voxels in the neighborhood around voxel 
\begin_inset Formula $i$
\end_inset

.
 It can be written similarly in the form 
\begin_inset Formula 
\[
h_{\text{SAD}}(x)=g_{\text{SAD}}(Kx)
\]

\end_inset

 by defining 
\begin_inset Formula $K\in\mathbb{R}^{8n\times n}$
\end_inset

 that computes the 8 forward differences in the 
\begin_inset Formula $3\times3$
\end_inset

 neighborhood and defining for 
\begin_inset Formula $u\in\mathbb{R}^{8n}$
\end_inset

 
\begin_inset Formula 
\[
g_{\text{SAD}}(u)=\sigma\Vert u\Vert_{1}=\sigma\sum_{i}\Vert u_{i}\Vert_{1}
\]

\end_inset

 where 
\begin_inset Formula $u_{i}\in\mathbb{R}^{8}$
\end_inset

.
 The proximal operator 
\begin_inset Formula $\prox_{\lambda g_{\text{ATV}}}(u)$
\end_inset

 is similar to the ATV case: 
\begin_inset Formula 
\begin{equation}
\prox_{\lambda g_{\text{ITV}}}(u_{i})=\sign(u_{i})\odot\max(0,\vert u_{i}\vert-\sigma).\label{eq:SAD-prox}
\end{equation}

\end_inset

The SAD prior has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "gregson2012stochastic"

\end_inset

 to produce excellent results in stochastic tomography reconstruction.
\end_layout

\begin_layout Section
Experiments
\begin_inset CommandInset label
LatexCommand label
name "sec:Experiments"

\end_inset


\end_layout

\begin_layout Subsection
Datasets
\end_layout

\begin_layout Standard
We present experiments on two simulated phantoms and one real dataset, see
 Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Phantoms"

\end_inset

.
 The phantoms are: the modified 2D Shepp-Logan head phantom 
\begin_inset CommandInset citation
LatexCommand cite
key "toft1996radon"

\end_inset

; and a 2D slice of the NCAT phantom 
\begin_inset CommandInset citation
LatexCommand cite
key "segars2002study"

\end_inset

.
 The phantoms were generated at a resolution of 
\begin_inset Formula $512\times512$
\end_inset

 pixels, and ground truth sinograms were generated in ASTRA using a fan
 beam geometry with 
\begin_inset Formula $888$
\end_inset

 detectors, isotropic pixels of 1 mm, isotropic detectors of 
\begin_inset Formula $1.0239$
\end_inset

 mm, and source-to-detector distance of 
\begin_inset Formula $949.075$
\end_inset

 mm.
 We assumed Poisson measurement noise with emitted intensity count 
\begin_inset Formula $I_{0}=10^{5}$
\end_inset

 to generate the noisy projections used.
\end_layout

\begin_layout Standard
The real dataset is a 2D slice of a 3D cone beam scan of a mouse from the
 Exxim Cobra software 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
available from 
\begin_inset CommandInset href
LatexCommand href
name "www.exxim-cc.com"
target "http://www.exxim-cc.com/"

\end_inset


\end_layout

\end_inset

.
 The data contains 194 projections (over 194 degrees) of a fan beam geometry
 with 512 detectors of size 0.16176 mm, source-to-detector distance of 529.29
 mm, source-to-isocenter distance of 395.73 mm, and reconstructed volume
 of 
\begin_inset Formula $512\times512$
\end_inset

 pixels of isotropic size 0.12 mm.
 We ran 500 iterations of BSSART with 
\begin_inset Formula $\alpha=0.1$
\end_inset

 to generate the 
\emph on
ground truth
\emph default
 volume.
 We measure performance in terms of SNR (signal-to-noise ratio) defined
 as 
\begin_inset Formula 
\[
\mbox{SNR}(x,\hat{x})=10\log\frac{\sum_{j}\hat{x}_{j}^{2}}{\sum_{j}\left(x_{j}-\hat{x}_{j}\right)^{2}}
\]

\end_inset

 where 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is the current estimate of the volume and 
\begin_inset Formula $\hat{x}\in\mathbb{R}^{n}$
\end_inset

 is the ground truth volume.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/phantom-ph_mod-sl-512.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/phantom-ph_ncat-512.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/phantom-ph_mouse-512.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The three datasets used.
 (c) shows the 
\emph on
ground truth
\emph default
 converged result from the projections.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Phantoms"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We clip the reconstruction estimate 
\begin_inset Formula $x$
\end_inset

 at the end of each inner iteration (i.e.
 after each update step) using this function 
\begin_inset Formula 
\[
\mbox{clip}(x)=\max(0,x)
\]

\end_inset

 to get rid of negative voxel values.
 All experiments in this section are on one core of an Intel Xeon E5-280
 2.7 GHz with 64 GB RAM.
 
\end_layout

\begin_layout Subsection
Iterative Algorithms Comparison
\begin_inset CommandInset label
LatexCommand label
name "sub:Iterative-Algorithms-Comparison"

\end_inset


\end_layout

\begin_layout Standard
We first compare the different iterative algorithms presented in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Iterative-Algorithms"

\end_inset

 on the three datasets.
 We set the number of subsets in OS-SQS to the number of projections to
 have a fair comparison with SART, since we noticed that increasing the
 number of subsets increases the convergence rate.
 All experiments in this section are run using ASTRA, where we implemented
 missing algorithms and modified existing ones to suit our needs e.g.
 compute SNR, report run times, etc.
 We compare different values of 
\begin_inset Formula $\alpha$
\end_inset

, namely 0.1, 1, and 1.99.
 We compare convergence per iteration since all methods are roughly equal
 in runtime, as each outer iteration contains (roughly) one forward and
 one backward projection.
 This is confirmed in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-time-iterative"

\end_inset

.
 Note that our implementation is not optimized for any of the methods, and
 the processing time is just an indication.
 We initialize all methods with uniform volume 
\begin_inset Formula $x^{(0)}=\mathbf{0}_{n}$
\end_inset

.
\end_layout

\begin_layout Standard
Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-iteration-iterative"

\end_inset

 shows the SNR per iteration for 15, 30, 90 projections for 30 iterations,
 while Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-num-proj-iterative"

\end_inset

 shows the the maximum SNR over 30 iterations for different number of equally
 distributed projections from 15 to 180.
 From the figures, we make the following conclusions:
\end_layout

\begin_layout Itemize
The simulated projections closely resemble the results from the real dataset,
 which suggests that the measurement noise model is reflective of real data.
\end_layout

\begin_layout Itemize
With fewer projections (15 or 30 projections), using larger values 
\begin_inset Formula $\alpha=1.99$
\end_inset

 gives faster and better convergence.
 
\end_layout

\begin_layout Itemize
With many projections, moderate values 
\begin_inset Formula $\alpha=1$
\end_inset

 produces a fast convergence that then falls off and is overtaken by 
\begin_inset Formula $\alpha=0.1$
\end_inset

.
\end_layout

\begin_layout Itemize
SART provides the fastest convergence within a handful of iterations, and
 is consistently better for fewer projections.
 However, it is overtaken by ART and others for many projections.
 This provides the motivation to use it in the proximal framework, since
 typically the tomography solver is invoked for only a few iterations per
 outer iteration of ADMM for example 
\begin_inset CommandInset citation
LatexCommand cite
key "ramani2012splitting"

\end_inset

.
\end_layout

\begin_layout Itemize
With more projections, e.g.
 90, we notice that the SNR for a few methods go up and then down.
 This doesn't mean, however, that they are not converging.
 The objective function is the projection error, and we confirmed it is
 in fact improving even though the SNR is decreasing.
 This can be explained by the fact of the presence of noise, and that at
 some point the algorithm starts fitting the noise in the measurements 
\begin_inset CommandInset citation
LatexCommand cite
key "herman2009fundamentals"

\end_inset

.
\end_layout

\begin_layout Itemize
Even though BICAV, SIRT, and BSSART have formal proofs of convergence, their
 convergence speed per iteration is in fact much lower than SART or (this
 version of) OS-SQS, that lack these proofs.
\end_layout

\begin_layout Itemize
The faster convergence and best results are achieved by SART, followed by
 ART, OS-SQS, and BICAV.
 They work better with 
\begin_inset Formula $\alpha=1$
\end_inset

 for few projections, and with 
\begin_inset Formula $\alpha=0.1$
\end_inset

 for more projections.
\end_layout

\begin_layout Itemize
CGLS, that was used before for solving tomography problems 
\begin_inset CommandInset citation
LatexCommand cite
key "ramani2012splitting,sidky2012convex"

\end_inset

, performs quite poorly compared to the other iterative algorithms.
\end_layout

\begin_layout Itemize
Using plain iterative methods does not give acceptable results with fewer
 projections.
 Thus we focus next on using regularizers in the proximal framework with
 SART, ART, OS-SQS, and BICAV and fewer projections, namely 30 projections.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_15-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_90-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_15-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_90-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_15-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_30-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_90-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Convergence of Iterative Algorithms.
 Plots show SNR per iteration.
 Solid lines have 
\begin_inset Formula $\alpha=1$
\end_inset

, dashed lines have 
\begin_inset Formula $\alpha=1.99$
\end_inset

, and dotted lines have 
\begin_inset Formula $\alpha=0.1$
\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:SNR-per-iteration-iterative"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_90-p_fan_t1-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_90-p_mouse_t1-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_90-p_mouse_t1-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
SNR per running time for 90 projections.
 Compare with Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-iteration-iterative"

\end_inset

 (bottom row).
 
\begin_inset CommandInset label
LatexCommand label
name "fig:SNR-per-time-iterative"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/max-snr-per_num_proj-ph_mod-sl-512_nt_poisson-nl_100000.000-it_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/max-snr-per_num_proj-ph_ncat-512_nt_poisson-nl_100000.000-it_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/max-snr-per_num_proj-ph_mouse-512_nt_gauss-nl_0.000-it_30-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Effect of the number of projections.
 Plots show the maximum SNR achieved over 30 iterations per number of projection
s used.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:SNR-per-num-proj-iterative"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Data Terms and Regularizers Comparison
\begin_inset CommandInset label
LatexCommand label
name "sub:Data-Terms-and-Regularizers-Comparison"

\end_inset


\end_layout

\begin_layout Standard
We compare the different data terms and regularizers defined in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Proximal-Framework"

\end_inset

.
 We solve the tomography proximal operator (step 3 in Alg.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:LADMM-algorithm"

\end_inset

) using 2 iterations of the SART proximal operator (from Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Prox-Operators"

\end_inset

), using 
\begin_inset Formula $\alpha=1.99$
\end_inset

 with for 15 and 30 projections and 
\begin_inset Formula $\alpha=1$
\end_inset

 for 90 projections (see Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Iterative-Algorithms-Comparison"

\end_inset

).
 We use 
\begin_inset Formula $\sigma=0.05$
\end_inset

 and 
\begin_inset Formula $\rho=25$
\end_inset

 for 15 projections; 
\begin_inset Formula $\sigma=0.1$
\end_inset

 and 
\begin_inset Formula $\rho=50$
\end_inset

 for 30 projections; 
\begin_inset Formula $\sigma=0.5$
\end_inset

 and 
\begin_inset Formula $\rho=200$
\end_inset

 for 90 projections; and set 
\begin_inset Formula $\mu=\nicefrac{1}{\rho\Vert K\Vert^{2}}$
\end_inset

.
 We initialize all methods with uniform volume 
\begin_inset Formula $x^{(0)}=\mathbf{0}_{n}$
\end_inset

.
 We estimated the matrix norm 
\begin_inset Formula $\Vert K\Vert$
\end_inset

 using the power method.
 Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-iter-data-term-and-reg-sart-prox"

\end_inset

 shows the results for the three datasets, where we plot against the number
 of SART iterations.
 We note the following: 
\end_layout

\begin_layout Itemize
Using the proximal framework provides significantly better results than
 the unregularized iterative methods in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Iterative-Algorithms-Comparison"

\end_inset

.
 This is expected since adding a powerful regularizer constrains the reconstruct
ion to better resemble the ground truth.
\end_layout

\begin_layout Itemize
The Poisson noise model 
\begin_inset Formula $f_{\text{P}}(\cdot)$
\end_inset

 is better than the Gaussian noise model 
\begin_inset Formula $f_{\text{G}}(\cdot)$
\end_inset

 for the three datasets, specially with more projections.
 This is consistent with the noise model used to generate the noisy simulated
 sinograms, and with the physical nosie model in the real dataset.
\end_layout

\begin_layout Itemize
With more projections, more regularization (higher 
\begin_inset Formula $\sigma$
\end_inset

) produces better results while for fewer projections less regularization
 is sufficient .
 This is expected because using more projections adds more constraints (rows
 in the projection matrix 
\begin_inset Formula $A$
\end_inset

) that need better regularization to get good results.
\end_layout

\begin_layout Itemize
The SAD regularizer is better for all datasets.
 ATV is better (or similar) on the synthetic datasets, while ITV is better
 on the mouse dataset.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_15-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_90-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_15-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_90-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_15-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_30-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/sart-prox-comp-per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_90-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
SNR per iteration for the Gaussian (
\emph on
solid
\emph default
 curves) and Poisson (
\emph on
dashed
\emph default
 curves)noise models with ITV (
\emph on
blue
\emph default
), ATV (
\emph on
red
\emph default
), and SAD (
\emph on
green
\emph default
) regularizers.
 The 
\emph on
black
\emph default
 curve shows the results for SART.
 See Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Data-Terms-and-Regularizers-Comparison"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:SNR-per-iter-data-term-and-reg-sart-prox"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Proximal Operators Comparison
\begin_inset CommandInset label
LatexCommand label
name "sub:Proximal-Operators-Comparison"

\end_inset


\end_layout

\begin_layout Standard
We compare the different proximal operators from Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Proximal-Operators"

\end_inset

 (SART, ART, OS-SQS, and BICAV) and Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Prox-Operators"

\end_inset

 using the best results from Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Data-Terms-and-Regularizers-Comparison"

\end_inset

 i.e.
 Poisson noise model and SAD regularizer.
 We set 
\begin_inset Formula $\sigma=0.1$
\end_inset

; 
\begin_inset Formula $\rho=50$
\end_inset

 for SART, ART, and BICAV, and 
\begin_inset Formula $\rho=1$
\end_inset

 for OS-SQS (which gave better results).
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status open

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/prox-comp-per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/prox-comp-per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/prox-comp-per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/prox-comp-per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/prox-comp-per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_30-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/prox-comp-per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_30-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
SNR per iteration for the Gaussian (
\emph on
solid
\emph default
 curves) and Poisson (
\emph on
dashed
\emph default
 curves)noise models with ITV (
\emph on
blue
\emph default
), ATV (
\emph on
red
\emph default
), and SAD (
\emph on
green
\emph default
) regularizers.
 The 
\emph on
black
\emph default
 curve shows the results for SART.
 See Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sub:Data-Terms-and-Regularizers-Comparison"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:SNR-per-iter-prox-operator-comparison"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Conclusions
\begin_inset CommandInset label
LatexCommand label
name "sec:Discussion-and-Conclusion"

\end_inset


\end_layout

\begin_layout Section
Acknowledgments
\end_layout

\begin_layout Standard
This work was supported by KAUST baseline and research center funding.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "I:/Documents/Research/Papers/papers"
options "bibtotoc,ieeetr"

\end_inset


\end_layout

\end_body
\end_document
