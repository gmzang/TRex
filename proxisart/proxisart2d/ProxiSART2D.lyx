#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass IEEEtran
\begin_preamble
\usepackage{algorithm}
\usepackage{algpseudocode}


\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator*{\argmax}{argmax}
\DeclareMathOperator{\prox}{prox}
\DeclareMathOperator{\diag}{diag}

% Stretch cells vertically
\usepackage{array}
\renewcommand*\arraystretch{1.5}
%\setlength{\extrarowheight}{2pt}

\usepackage{babel}
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-15
\fontencoding T1
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 2
\use_package amssymb 2
\use_package cancel 0
\use_package esint 1
\use_package mathdots 0
\use_package mathtools 0
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 0
\use_package undertilde 0
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
ProxiSART: A Proximal Framework for Robust X-Ray Tomography Reconstruction
 using SART
\end_layout

\begin_layout Author
Mohamed Aly, 
\begin_inset Flex Flex:IEEE membership
status collapsed

\begin_layout Plain Layout
Member, IEEE
\end_layout

\end_inset

,
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
M.
 Aly is with the Visual Computing Center, KAUST, KSA
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% and
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

% the Computer Eng.
 Dept, Cairo University, Egypt%
\end_layout

\end_inset


\end_layout

\end_inset

, Guangming Zang, 
\begin_inset Flex Flex:IEEE membership
status collapsed

\begin_layout Plain Layout
Student Member, IEEE
\end_layout

\end_inset

, 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
G.
 Zang is with the Visual Computing Center, KAUST, KSA
\end_layout

\end_inset

 Wolfgang Heidrich, 
\begin_inset Flex Flex:IEEE membership
status collapsed

\begin_layout Plain Layout
Member, IEEE
\end_layout

\end_inset

, 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
W.
 Heidrich is with the Visual Computing Center, KAUST, KSA
\end_layout

\end_inset

 and Peter Wonka, 
\begin_inset Flex Flex:IEEE membership
status collapsed

\begin_layout Plain Layout
Member, IEEE
\end_layout

\end_inset

, 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
P.
 Wonka is with the Visual Computing Center, KAUST, KSA
\end_layout

\end_inset

 
\end_layout

\begin_layout Abstract
We present ProxiSART, a flexible proximal framework for robust X-ray tomographic
 reconstruction based on the Simultaneous Algebraic Reconstruction Technique
 (SART).
 We conduct a thorough comparison between different iterative reconstruction
 methods and establish that SART is the best algorithm in terms of reconstructio
n quality for sparse-view and noisy-measurement situations.
 We then focus on SART and derive its proximal operator.
 We show the flexibility of the framework by deriving solvers for different
 data terms including L1, L2, and weighted L2; and by plugging in different
 powerful regularizers.
 We compare our framework to state-of-the-art methods, and show superior
 quality on both synthetic and real datasets.
\end_layout

\begin_layout Keywords
Image reconstruction, X-ray imaging and computed tomography, Simultaneous
 Algebraic Reconstruction Technique, SART, Proximal Algorithms, Cone beam
 X-ray tomography 
\end_layout

\begin_layout Section
Introduction
\begin_inset CommandInset label
LatexCommand label
name "sec:Introduction"

\end_inset


\end_layout

\begin_layout Standard
Reducing the dosage in X-ray tomography is a very important issue in medical
 applications, since long term exposure to X-rays can have adverse health
 effects.
 This can be done in at least two ways: (a) reducing the X-ray beam power,
 which leads to increased measurement noise at the detectors; or (b) acquiring
 fewer projections to reduce the acquisition time 
\begin_inset CommandInset citation
LatexCommand cite
key "herman2009fundamentals"

\end_inset

.
 This makes the reconstruction problem even more ill-posed, since less informati
on is collected from the volume to be reconstructed; and one has to use
 non-linear regularizers (priors) to achieve a reasonable result.
 This is typically done using iterative solvers 
\begin_inset CommandInset citation
LatexCommand cite
key "thibault2007three,zhang2014model"

\end_inset

.
\end_layout

\begin_layout Standard
Iterative algorithms for X-ray tomography reconstruction have been around
 for years.
 In fact, one of the first implemented tomography reconstruction algorithm
 was an iterative one, the Algebraic Reconstruction Technique (ART) 
\begin_inset CommandInset citation
LatexCommand cite
key "kak2001principles,gordon1970algebraic,gordon1971reconstruction"

\end_inset

.
 However, non-iterative, transform-based algorithms, such as the filtered
 back projection (FBP) 
\begin_inset CommandInset citation
LatexCommand cite
key "ramachandran1971three,shepp1974fourier,feldkamp1984practical"

\end_inset

, have been more popular due to their speed and low computational cost.
 In fact, most commercial X-ray CT scanners employ some variant of FBP in
 their reconstruction software 
\begin_inset CommandInset citation
LatexCommand cite
key "pan2009commercial"

\end_inset

.
 Recently, interest has been ignited again in iterative algorithms because,
 although they are more computationally demanding, they are much more flexible
 and yield superior reconstruction quality by employing powerful priors.
 
\end_layout

\begin_layout Standard
Thus, in this paper, we study iterative reconstruction techniques.
 We conduct a thorough comparison of the famous iterative algorithms including
 SART (Simultaneous Algebraic Reconstruction Technique) 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset

, ART 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset

, SIRT (Simultaneous Iterative Reconstruction Technique) 
\begin_inset CommandInset citation
LatexCommand cite
key "gilbert1972iterative"

\end_inset

, BSSART (Block Simplified SART) 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset

, BICAV (Block Iterative Component Averaging) 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2001bicav"

\end_inset

, Conjugate Gradient 
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical"

\end_inset

, and OS-SQS (Ordered-Subset Separable Quadratic Surrogates) 
\begin_inset CommandInset citation
LatexCommand cite
key "depierro1994modified,hudson1994accelerated,erdogan1999ordered,kim2013accelerating,nien2015fast"

\end_inset

.
 We establish that SART 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset

 provides the best performance in the sparse view and noisy measurements
 situations.
 This motivates us to focus on SART for the rest of our development.
\end_layout

\begin_layout Standard
We then describe our framework, which is based on using proximal algorithms
 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2011distributed,parikh2013proximal"

\end_inset

 together with SART.
 We derive proximal operators for SART, BICAV, and OS-SQS, and show how
 to use these proximal operators to minimize different data fitting terms,
 including least squares (LS) that assumes a Gaussian noise model, weighted
 least squares (WLS) that assumes an approximation to a Poisson noise model
 
\begin_inset CommandInset citation
LatexCommand cite
key "clinthorne1993preconditioning"

\end_inset

, and least absolute deviation (LAD) 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2012convex"

\end_inset

.
 We compare the proximal operators using a Total Variation (TV) prior 
\begin_inset CommandInset citation
LatexCommand cite
key "rudin1992nonlinear"

\end_inset

 and establish that the SART proximal operator provides the best performance.
 
\end_layout

\begin_layout Standard
Finally we compare our framework to state of the art methods, namely the
 Augmented Lagrangian method from 
\begin_inset CommandInset citation
LatexCommand cite
key "ramani2012splitting"

\end_inset

 and the OS-SQS momentum method from 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2015combining"

\end_inset

, and show that our framework gives superiror reconstruction quality.
\end_layout

\begin_layout Standard
In summary, we provide the following contributions:
\end_layout

\begin_layout Enumerate
We perform a thorough experimental comparison of famous iterative reconstruction
 methods.
\end_layout

\begin_layout Enumerate
We derive proximal operators for SART, BICAV, and OS-SQS, and compare them.
\end_layout

\begin_layout Enumerate
We derive solvers for different data terms, namely LS, WLS, and LAD, using
 the derived proximal operator.
\end_layout

\begin_layout Enumerate
We compare our framework to state of the art methods and show that it produces
 superior reconstructions.
\end_layout

\begin_layout Enumerate
We make our code, which is based on the ASTRA toolbox 
\begin_inset CommandInset citation
LatexCommand cite
key "van2015astra"

\end_inset

, publicly available.
\end_layout

\begin_layout Section
Related Work
\begin_inset CommandInset label
LatexCommand label
name "sec:Related-Work"

\end_inset


\end_layout

\begin_layout Standard
There are two general approaches for X-ray tomography reconstruction: transform-
based methods and iterative methods 
\begin_inset CommandInset citation
LatexCommand cite
key "kak2001principles,herman2009fundamentals"

\end_inset

.
 Transform methods rely on the Radon transform and its inverse introduced
 in 1917.
 The most widely used reconstruction method is the Filtered Backprojection
 (FBP) algorithm introduced 
\begin_inset CommandInset citation
LatexCommand cite
key "herman2009fundamentals,kak2001principles"

\end_inset

.
 Transform methods are usually viewed as much faster than iterative methods,
 and have therefore been the method of choice for X-ray scanner manufacturers
 
\begin_inset CommandInset citation
LatexCommand cite
key "pan2009commercial"

\end_inset

.
\end_layout

\begin_layout Standard
Iterative methods on the other hand use algebraic techniques to solve the
 reconstruction problem.
 They generally model the problem as a linear system and solve it using
 established numerical methods 
\begin_inset CommandInset citation
LatexCommand cite
key "herman2009fundamentals"

\end_inset

.
 ART, and its many variants, are among the best known iterative reconstruction
 algorithms 
\begin_inset CommandInset citation
LatexCommand cite
key "gordon1970algebraic,lent1977convergent,shepp1982maximum,censor1983finite,andersen1984simultaneous,andersen1989algebraic"

\end_inset

.
 They use variations of the projection method of Kaczmarz 
\begin_inset CommandInset citation
LatexCommand cite
key "kaczmarz1937angenaherte"

\end_inset

 and have modest memory requirements, and have been shown to yield better
 reconstruction results than transform methods.
 They are matrix free, and work without having to explicitly store the system
 matrix.
 OS-SQS and related methods 
\begin_inset CommandInset citation
LatexCommand cite
key "depierro1994modified,hudson1994accelerated,erdogan1999ordered,kim2013accelerating,nien2015fast"

\end_inset

 are closely related to ART and have similar properties to SIRT 
\begin_inset CommandInset citation
LatexCommand cite
key "gregor2015comparison"

\end_inset

.
 The have also been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2015combining"

\end_inset

 to be accelerated using momentum techniques.
\end_layout

\begin_layout Standard
Iterative methods provide more flexibility in incorporating prior information
 into the reconstruction process.
 For example, instead of assuming a Gaussian noise model and minimizing
 a least squares data term, one can easily use iterative methods with other
 noise models.
 For example, a Poisson noise model 
\begin_inset CommandInset citation
LatexCommand cite
key "clinthorne1993preconditioning,depierro1994modified,elbakri2002statistical,wang2006penalized,thibault2007three"

\end_inset

.
 boils down to solving WLS problem instead.
 Priors are also easy to use with iterative methods.
 For example, the Total Variation 
\begin_inset CommandInset citation
LatexCommand cite
key "rudin1992nonlinear"

\end_inset

 prior has been used for tomography reconstruction 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2008image,mory2012ecg"

\end_inset

.
\end_layout

\begin_layout Standard
Proximal algorithms have been widely used in many problems in machine learning
 and signal processing 
\begin_inset CommandInset citation
LatexCommand cite
key "bauschke2011convex,combettes2011proximal,boyd2011distributed,parikh2013proximal"

\end_inset

.
 They have also been used in tomography reconstruction.
 For example, 
\begin_inset CommandInset citation
LatexCommand cite
key "mory2012ecg"

\end_inset

 used the Alternating Direction Method of Multipliers (ADMM) 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2011distributed"

\end_inset

 with total variation prior, where the data term was optimized using CG
 
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2012convex"

\end_inset

 discussed using the Chambolle-Pock algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "chambolle2011first"

\end_inset

 for tomography reconstruction with different priors.
 
\begin_inset CommandInset citation
LatexCommand cite
key "ramani2012splitting"

\end_inset

 used ADMM with Preconditioned CG 
\begin_inset CommandInset citation
LatexCommand cite
key "nocedal2006numerical"

\end_inset

 for optimizing the weighted least squares data term.
 
\begin_inset CommandInset citation
LatexCommand cite
key "nien2015fast"

\end_inset

 used Linearized ADMM 
\begin_inset CommandInset citation
LatexCommand cite
key "parikh2013proximal"

\end_inset

 (also known as Inexact Split Uzawa 
\begin_inset CommandInset citation
LatexCommand cite
key "esser2010general"

\end_inset

) with Ordered Subset-based methods 
\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered"

\end_inset

 for optimizing the data term and FISTA 
\begin_inset CommandInset citation
LatexCommand cite
key "beck2009fast"

\end_inset

 for optimizing the prior term.
 However, none of these methods used SART as their data term solver, which
 provides superior reconstruction as we will next.
\end_layout

\begin_layout Standard
There are currently a number of open source software packages for tomography
 reconstruction.
 SNARK09 
\begin_inset CommandInset citation
LatexCommand cite
key "klukowska2013snark09"

\end_inset

 is one of the oldest.
 The Reconstruction ToolKit (RTK) 
\begin_inset CommandInset citation
LatexCommand cite
key "rit2014reconstruction"

\end_inset

 is a high performance C++ toolkit focusing on 3D cone beam reconstruction
 that is based on the image processing package Insight ToolKit (ITK).
 It includes implementations of several algorithms, including FDK, SART,
 and an ADMM TV-regularized solver with CG 
\begin_inset CommandInset citation
LatexCommand cite
key "mory2012ecg"

\end_inset

.
 The ASTRA toolbox 
\begin_inset CommandInset citation
LatexCommand cite
key "van2015astra"

\end_inset

 is a Matlab-based GPU-accelerated toolbox for tomography reconstruction.
 It includes implementations of several algorithms, including SART, SIRT,
 FBP, among others.
 We modify and extend ASTRA to implement our algorithms and generate the
 experiments in this paper.
\end_layout

\begin_layout Section
Iterative Algorithms
\begin_inset CommandInset label
LatexCommand label
name "sec:Iterative-Algorithms"

\end_inset


\end_layout

\begin_layout Subsection
Overview
\begin_inset CommandInset label
LatexCommand label
name "sub:Overview-Iterative-Algorithms"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
protect
\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:Iterative-Algorithm"

\end_inset

Outline of Iterative Algorithms
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1]
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Require
\end_layout

\end_inset

 
\begin_inset Formula $A\in\mathbb{R}{}^{m\times n}$
\end_inset

, 
\begin_inset Formula $\alpha\in\mathbb{R}$
\end_inset

, 
\begin_inset Formula $p\in\mathbb{R}{}^{m}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 Initialize: 
\begin_inset Formula $x^{(0)}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset Formula $t=1\ldots T$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

subsets 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset


\begin_inset Formula $x^{(t+1)}=x^{(t)}+\alpha\Delta x^{(t)}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset


\begin_inset Formula $x^{(t+1)}=\mbox{clip}(x^{(t+1)})$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Return
\end_layout

\end_inset

 volume reconstruction 
\begin_inset Formula $x\in\mathbb{R}{}^{n}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The tomography problem can be simplified to solving a linear system 
\begin_inset CommandInset citation
LatexCommand cite
key "kak2001principles,herman2009fundamentals"

\end_inset

 
\begin_inset Formula 
\begin{equation}
Ax=p,\label{eq:linear-system}
\end{equation}

\end_inset

where 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is the unknown volume in vector form, 
\begin_inset Formula $A\in\mathbb{R}^{m\times n}$
\end_inset

 is the projection system matrix, and 
\begin_inset Formula $p\in\mathbb{R}^{m}$
\end_inset

 represents the measured line projections (sinogram).
 The iterative algorithms that we study in this work all have the same general
 outline in Alg.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:Iterative-Algorithm"

\end_inset

, but differ in the update formula in step 4.
 The subset 
\begin_inset Formula $S$
\end_inset

 in step 3 can be only 1 projection ray as in ART i.e.
 there are 
\begin_inset Formula $m$
\end_inset

 subsets 
\begin_inset Formula $S_{i}=\{i\,|\, i=1\ldots m\}$
\end_inset

; can contain all the rays in a projection view as in SART i.e.
 there are 
\begin_inset Formula $m/s$
\end_inset

 subsets where 
\begin_inset Formula $s$
\end_inset

 is the number of projection views; or can contain the whole projection
 rays as in SIRT i.e.
 there is only one subset 
\begin_inset Formula $S=\{1,\ldots,m\}$
\end_inset

.
 The update step 
\begin_inset Formula $\Delta x^{(t)}$
\end_inset

 is typically a function of (a subset of) the forward projection error 
\begin_inset Formula $p_{S}-A_{S}x^{(t)}$
\end_inset

 that is then backprojected with some normalization procedure.
 It can take the form 
\begin_inset Formula 
\[
\Delta x^{(t)}=\Phi\left(A_{S}^{T},p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

where the function 
\begin_inset Formula $\Phi(\cdot)$
\end_inset

 computes the required update, see below.
 This can be seen as an approximation to the actual gradient 
\begin_inset Formula $A^{T}(p-Ax)$
\end_inset

 of the least square objective 
\begin_inset Formula 
\[
\argmin_{x}\Vert Ax-p\Vert_{2}^{2}
\]

\end_inset

 and so these algorithms can be veiwed as variations of (stochastic) gradient
 descent 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2015combining"

\end_inset

 where they differ on how they approximate the gradient.
 We also notice that the inner loop in step 3 for all these algorithms takes
 roughly the same time, since it involves one full sweep over the rows of
 
\begin_inset Formula $A$
\end_inset

.
\end_layout

\begin_layout Standard
Below we will quickly review the different methods, and Table 
\begin_inset CommandInset ref
LatexCommand ref
reference "tab:Iterative-Methods"

\end_inset

 provides a summary of their important properties.
\end_layout

\begin_layout Standard
\begin_inset Float table
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
center
\end_layout

\end_inset


\begin_inset Tabular
<lyxtabular version="3" rows="8" columns="5">
<features rotate="0" booktabs="true" tabularvalignment="middle">
<column alignment="center" valignment="top" width="0pt">
<column alignment="center" valignment="top">
<column alignment="center" valignment="middle" width="3text%">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Method
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Update Step
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Subset
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Solved Problem
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Converges
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
ART 
\begin_inset CommandInset citation
LatexCommand cite
key "gordon1970algebraic"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{p_{i}-\sum_{k}a_{ik}x_{k}^{(t)}}{\sum_{k}a_{ik}^{2}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha A_{i}^{T}R^{-1}\left(p_{i}-A_{i}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one ray
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x^{\star}= & \argmin_{x}\Vert x\Vert_{2}^{2}\\
 & \mbox{s.t. }Ax=p
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SIRT 
\begin_inset CommandInset citation
LatexCommand cite
key "gilbert1972iterative"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{1}{\sum_{i=1}^{m}a_{ij}}\sum_{i=1}^{m}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha C^{-1}A^{T}R^{-1}\left(p-Ax^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
all rays
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{R^{-1}}^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
SART 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{1}{\sum_{i\in S}a_{ij}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha C_{S}^{-1}A_{S}^{T}R^{-1}\left(p-A_{S}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one view
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x^{\star}\approx & \argmin_{x}\Vert x\Vert_{2}^{2}\\
 & \mbox{s.t. }Ax=p
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
No
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BSSART 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{1}{\sum_{i=1}^{m}a_{ij}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha C^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one view
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x^{\star}= & \argmin_{x}\Vert x\Vert_{2}^{2}\\
 & \mbox{s.t. }Ax=p
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
BICAV 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2001bicav"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\alpha\frac{1}{\sum_{i\in S}\{a_{ij}\ne0\}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}^{2}}a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha C_{S}^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one view
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x^{\star}= & \argmin_{x}\Vert x\Vert_{2}^{2}\\
 & \mbox{s.t. }Ax=p
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
OS-SQS 
\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\begin{aligned}x_{j}^{(t+1)} & =x_{j}^{(t)}+\frac{\alpha s}{\left(\sum_{k=1}^{m}a_{kj}\sum_{i=1}^{n}a_{ki}\right)}\sum_{i\in S}\left(p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}\right)a_{ij}\\
x^{(t+1)} & =x^{(t)}+\alpha sC^{-1}A_{S}^{T}\left(p_{S}-A_{S}x^{(t)}\right)
\end{aligned}
$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
one view
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x^{\star}\approx\Vert Ax-p\Vert_{2}^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
No
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
CGLS 
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical,fessler1999conjugate"

\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x^{(t+1)}=x^{(t)}+\alpha_{t}\Phi\left(A^{T}(p-Ax^{(t)})\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
all rays
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $x^{\star}=\Vert Ax-p\Vert_{2}^{2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Yes
\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Summary of iterative methods and their properties.
\begin_inset CommandInset label
LatexCommand label
name "tab:Iterative-Methods"

\end_inset

 The first line in the update step is voxel-based, while the second is the
 matrix formulation.
 See Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "sec:Iterative-Algorithms"

\end_inset

 for details.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard

\series bold
ART
\series default
 
\begin_inset CommandInset citation
LatexCommand cite
key "gordon1970algebraic,gordon1971reconstruction"

\end_inset

 is the first algebraic method, and is based on Kaczmarz alternating projection
 algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "kaczmarz1937angenaherte"

\end_inset

.
 ART treats each row of 
\begin_inset Formula $A$
\end_inset

 in turn, and updates the current estimate according to 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{p_{i}-\sum_{k}a_{ik}x_{k}^{(t)}}{\sum_{k}a_{ik}^{2}}a_{ij}\mbox{ for }i=1\ldots m,
\end{eqnarray*}

\end_inset

 where 
\begin_inset Formula $x_{j}^{(t)}$
\end_inset

 is the 
\begin_inset Formula $j$
\end_inset

th voxel at time 
\begin_inset Formula $t$
\end_inset

, 
\begin_inset Formula $a_{ij}$
\end_inset

 is the entry in the 
\begin_inset Formula $i$
\end_inset

th row and 
\begin_inset Formula $j$
\end_inset

th column of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $\alpha\in\mathbb{R}$
\end_inset

 is the relaxation parameter.
 This update is performed once each row of 
\begin_inset Formula $A$
\end_inset

, and one iteration includes a full pass over all the 
\begin_inset Formula $m$
\end_inset

 rows.
 The term 
\begin_inset Formula $\sum_{k}a_{ik}x_{k}^{(t)}$
\end_inset

 is the forward projection of the volume estimate for the 
\begin_inset Formula $i$
\end_inset

th ray (equation or row), the difference in the numerator is the projection
 error, that is then backprojected by multiplying the transpose of the 
\begin_inset Formula $i$
\end_inset

th row.
 It has been shown that ART converges to a least-norm solution to the consistent
 system of equations 
\begin_inset CommandInset citation
LatexCommand cite
key "tanabe1971projection"

\end_inset

 i.e.
 it solves 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert x\Vert_{2}^{2}\mbox{ s.t. }Ax=p.
\]

\end_inset

 In matrix notation, this can be also expressed as 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha A_{i}^{T}R^{-1}\left(p_{i}-A_{i}x^{(t)}\right)
\]

\end_inset

 where 
\begin_inset Formula $A_{i}\in\mathbb{R}^{n}$
\end_inset

 is the 
\begin_inset Formula $i$
\end_inset

th row of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $R\in\mathbb{R}^{m\times m}=\diag(r_{i})$
\end_inset

 is a diagonal matrix where 
\begin_inset Formula $r_{i}=\sum_{j}a_{ij}^{2}=\Vert A_{i}\Vert_{2}^{2}$
\end_inset

 is the squared-norm of the 
\begin_inset Formula $i$
\end_inset

th row 
\begin_inset Formula $A_{i}$
\end_inset

.
 
\end_layout

\begin_layout Standard

\series bold
SIRT 
\series default

\begin_inset CommandInset citation
LatexCommand cite
key "gilbert1972iterative"

\end_inset

 performs the updates 
\emph on
simultaneously 
\emph default
i.e.
 updates the volume once instead of updating it per each row 
\begin_inset Formula $A_{i}$
\end_inset

.
 The update equation becomes 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{1}{\sum_{i=1}^{m}a_{ij}}\sum_{i=1}^{m}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}.
\end{eqnarray*}

\end_inset

 In matrix form this becomes 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha C^{-1}A^{T}R^{-1}\left(p-Ax^{(t)}\right)
\]

\end_inset

 where 
\begin_inset Formula $C\in\mathbb{R}^{n\times n}=\diag(c_{j})$
\end_inset

 is a diagonal matrix whore 
\begin_inset Formula $c_{j}=\sum_{i}a_{ij}$
\end_inset

 is the sum of column 
\begin_inset Formula $j$
\end_inset

 of 
\begin_inset Formula $A$
\end_inset

 and 
\begin_inset Formula $R=\diag(r_{i})$
\end_inset

 where 
\begin_inset Formula $r_{i}=\sum_{j}a_{ij}$
\end_inset

 is the sum of row 
\begin_inset Formula $i$
\end_inset

 of 
\begin_inset Formula $A$
\end_inset

.
 In each iteration, SIRT performs a full forward projection 
\begin_inset Formula $Ax^{(t)}$
\end_inset

, computes the residual, and then backprojects it.
 The diagonal matrices 
\begin_inset Formula $R$
\end_inset

 and 
\begin_inset Formula $C$
\end_inset

 perform scaling for the relevant entries.
 It has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block,jiang2003convergence"

\end_inset

 that SIRT converges to a solution of the WLS problem 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{R^{-1}}^{2}=\min_{x}(Ax-p)^{T}R^{-1}(Ax-p)
\]

\end_inset

for 
\begin_inset Formula $0<\alpha<2$
\end_inset

.
 SIRT has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "gregor2015comparison"

\end_inset

 to be closely related, and in fact quite equivalent in terms of convergence
 properties, to the OS-SQS method.
 It has also been shown to converge best for 
\begin_inset Formula $\alpha=2-\epsilon$
\end_inset

 for a small 
\begin_inset Formula $0<\epsilon\ll1$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
SART 
\series default

\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic"

\end_inset

 is a tradeoff between ART and SIRT, in that it updates the volume after
 processing all the rows in a particular projection view.
 The update equation becomes 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{1}{\sum_{i\in S}a_{ij}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}
\end{eqnarray*}

\end_inset

for 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 where the summation 
\begin_inset Formula $i\in S$
\end_inset

 is across all rows (rays) in projection view 
\begin_inset Formula $S$
\end_inset

 for all views 
\begin_inset Formula $\mathcal{S}$
\end_inset

.
 This has been shown to provide faster convergence than ART and better reconstru
ction results than SIRT 
\begin_inset CommandInset citation
LatexCommand cite
key "mueller2000rapid,mueller1999fast"

\end_inset

.
 In matrix form 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha C_{S}^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

 where 
\begin_inset Formula $A_{S}\in\mathbb{R}^{s\times n}$
\end_inset

 contains the 
\begin_inset Formula $s$
\end_inset

 rows in projection 
\begin_inset Formula $S$
\end_inset

, 
\begin_inset Formula $p_{S}$
\end_inset

 contains the corresponding 
\begin_inset Formula $s$
\end_inset

 rays from the projection measurements, 
\begin_inset Formula $R$
\end_inset

 contains the row sums as in SIRT, while 
\begin_inset Formula $C_{S}=\diag(c_{j}^{S})$
\end_inset

 contains the column sums restricted to the rows in 
\begin_inset Formula $S$
\end_inset

 i.e.
 
\begin_inset Formula $c_{j}^{S}=\sum_{i\in S}a_{ij}$
\end_inset

.
 There is still no proof of convergence for SART in the literature, but
 there are proofs for variants of SART, such as BSSART and BICAV below,
 that converge to a minimum-norm solution like ART.
 This motivates us to assume that SART solves approximately the minimum-norm
 solution 
\begin_inset Formula 
\[
x^{\star}\approx\argmin_{x}\Vert x\Vert_{2}^{2}\mbox{ s.t. }Ax=p.
\]

\end_inset


\end_layout

\begin_layout Standard

\series bold
BSSART
\series default
 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset

 is a slight simplification of SART, where the column sums in the update
 equation are done over 
\emph on
all
\emph default
 the rows of 
\begin_inset Formula $A$
\end_inset

 instead of just over the rows in the current view, which is quite similar
 to SIRT.
 The update equation becomes 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{1}{\sum_{i=1}^{m}a_{ij}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}}a_{ij}
\end{eqnarray*}

\end_inset

 for 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 , which provides a slight speedup since the column sums are now independent
 of the iteration.
 The matrix formulation becomes 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha C^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

 where the diagonal matrices are both indepdendent of the projection view
 
\begin_inset Formula $S$
\end_inset

 as in SIRT.
 This has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset

 to converge to the minimum norm solution 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert x\Vert_{2}^{2}\mbox{ s.t. }Ax=p
\]

\end_inset

 as ART for 
\begin_inset Formula $0<\alpha<2$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
BICAV
\series default
 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2001bicav,censor2002block"

\end_inset

 is another closely-related algorithm to SART.
 It updates the volume after each projection view according to 
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{1}{c_{j}^{S}}\sum_{i\in S}\frac{p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}}{\sum_{k=1}^{n}a_{ik}^{2}}a_{ij}
\end{eqnarray*}

\end_inset

for 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 where 
\begin_inset Formula $c_{j}^{S}=\sum_{i\in S}\{a_{ij}\ne0\}$
\end_inset

 and 
\begin_inset Formula $\{a_{ij}\ne0\}=1$
\end_inset

 when 
\begin_inset Formula $a_{ij}$
\end_inset

 is non-zero is 0 otherwise.
 The difference from SART is that it computes the squared norm of the rows
 of 
\begin_inset Formula $A$
\end_inset

 and counts the number of non-zero entries in the columns of 
\begin_inset Formula $A$
\end_inset

.
 The matrix formulation is 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha C_{S}^{-1}A_{S}^{T}R^{-1}\left(p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

 where now 
\begin_inset Formula $r_{i}=\sum_{j}a_{ij}^{2}=\Vert A_{i}\Vert_{2}^{2}$
\end_inset

 and 
\begin_inset Formula $C_{S}=\diag(c_{j}^{S})$
\end_inset

.
 It is shown 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block"

\end_inset

 that BICAV converges to the minimum-norm solution 
\begin_inset Formula 
\[
\min_{x}\Vert x\Vert^{2}\mbox{ s.t. }Ax=p
\]

\end_inset

 for 
\begin_inset Formula $0<\alpha<2$
\end_inset

.
\end_layout

\begin_layout Standard

\series bold
OS-SQS 
\series default

\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered,kim2013accelerating,kim2015combining,nien2015fast"

\end_inset

 is closely related to SART.
 It is usually derived from a majorization-minimization perspective 
\begin_inset CommandInset citation
LatexCommand cite
key "depierro1994modified,erdogan1999ordered,kim2013accelerating,kim2015combining"

\end_inset

, but with a specific choice of surrogate functions and parameters 
\begin_inset CommandInset citation
LatexCommand cite
key "kim2013accelerating"

\end_inset

 the update equation becomes
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{s}{c_{j}}\sum_{i\in S}\left(p_{i}-\sum_{k=1}^{n}a_{ik}x_{k}^{(t)}\right)a_{ij}
\end{eqnarray*}

\end_inset

for 
\begin_inset Formula $S\in\mathcal{S}$
\end_inset

 where 
\begin_inset Formula $s$
\end_inset

 is the number of subsets 
\begin_inset Formula $S$
\end_inset

 in 
\begin_inset Formula $\mathcal{S}$
\end_inset

 (number of inner iterations), 
\begin_inset Formula $c_{j}=\left(\sum_{k=1}^{m}a_{kj}\sum_{i=1}^{n}a_{ki}\right)$
\end_inset

, and in general the set 
\begin_inset Formula $S$
\end_inset

 can contain more than one projection view.
 In matrix form it becomes 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha sC^{-1}A_{S}^{T}\left(p_{S}-A_{S}x^{(t)}\right)
\]

\end_inset

 where the matrix 
\begin_inset Formula $C=\diag(A^{T}A\mathbf{1}_{m})=\diag(c_{j})$
\end_inset

 where 
\begin_inset Formula $\mathbf{1}_{m}$
\end_inset

 is the vector of 
\begin_inset Formula $m$
\end_inset

 ones.
 OS-SQS is a special case of the SQS method, which processes all the rows
 of 
\begin_inset Formula $A$
\end_inset

 at once like SIRT.
 SQS has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "erdogan1999ordered"

\end_inset

 to converge to a least square solution 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{2}^{2},
\]

\end_inset

 and special case of 
\emph on
relaxed
\emph default
 OS-SQS converges, where the relaxation parameter becomes iteration-dependent
 and decreases over time 
\begin_inset CommandInset citation
LatexCommand cite
key "ahn2003globally"

\end_inset

.
 However, OS-SQS with fixed 
\begin_inset Formula $\alpha$
\end_inset

 is not known to converge.
 Therefore, like SART, we assume that it solves the LS problem above approximate
ly.
 
\end_layout

\begin_layout Standard

\series bold
CGLS
\series default
 
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical,fessler1999conjugate"

\end_inset

 is a type of Conjugate Gradient that solves the least squares normal equations
 directly.
 Like SIRT, it updates the constraint once per full sweep over the projection
 rays.
 The update equation in matrix notation is 
\begin_inset Formula 
\[
x^{(t+1)}=x^{(t)}+\alpha_{t}\Phi(A^{T}(p-Ax^{(t)}))
\]

\end_inset

 where the update step is a function of the backprojection of the projection
 error, and the parameter 
\begin_inset Formula $\alpha_{t}$
\end_inset

 depends on the specific version of CGLS (here we use the Fletcher-Reeves
 update rule
\begin_inset CommandInset citation
LatexCommand cite
key "bjorck1996numerical"

\end_inset

).
 CGLS is proven to be convergent to the solution of the LS problem 
\begin_inset Formula 
\[
x^{\star}=\argmin_{x}\Vert Ax-p\Vert_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Subsection
Experimental Comparison
\begin_inset CommandInset label
LatexCommand label
name "sub:Experimental-Comparison-Iterative-Algorithms"

\end_inset


\end_layout

\begin_layout Standard
We present experiments on two simulated phantoms and one real dataset, see
 Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Phantoms"

\end_inset

.
 The phantoms are: the modified 2D Shepp-Logan head phantom 
\begin_inset CommandInset citation
LatexCommand cite
key "toft1996radon"

\end_inset

; and a 2D slice of the NCAT phantom 
\begin_inset CommandInset citation
LatexCommand cite
key "segars2002study"

\end_inset

.
 The phantoms were generated at a resolution of 
\begin_inset Formula $512\times512$
\end_inset

 pixels, and ground truth sinograms were generated in ASTRA using a fan
 beam geometry with 
\begin_inset Formula $888$
\end_inset

 detectors, isotropic pixels of 1 mm, isotropic detectors of 
\begin_inset Formula $1.0239$
\end_inset

 mm, and source-to-detector distance of 
\begin_inset Formula $949.075$
\end_inset

 mm.
 We assumed Poisson measurement noise with emitted intensity count 
\begin_inset Formula $I_{0}=10^{5}$
\end_inset

 to generate the noisy projections used.
\end_layout

\begin_layout Standard
The real dataset is a 2D slice of a 3D cone beam scan of a mouse from the
 Exxim Cobra software 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
available from 
\begin_inset CommandInset href
LatexCommand href
name "www.exxim-cc.com"
target "http://www.exxim-cc.com/"

\end_inset


\end_layout

\end_inset

.
 The data contains 194 projections (over 194 degrees) of a fan beam geometry
 with 512 detectors of size 0.16176 mm, source-to-detector distance of 529.29
 mm, source-to-isocenter distance of 395.73 mm, and reconstructed volume
 of 
\begin_inset Formula $512\times512$
\end_inset

 pixels of isotropic size 0.12 mm.
 We ran 500 iterations of BSSART with 
\begin_inset Formula $\alpha=0.1$
\end_inset

 to generate the 
\emph on
ground truth
\emph default
 volume.
 We measure performance in terms of SNR (signal-to-noise ratio) defined
 as 
\begin_inset Formula 
\[
\mbox{SNR}(x,\hat{x})=10\log\frac{\sum_{j}\hat{x}_{j}^{2}}{\sum_{j}\left(x_{j}-\hat{x}_{j}\right)^{2}}
\]

\end_inset

 where 
\begin_inset Formula $x\in\mathbb{R}^{n}$
\end_inset

 is the current estimate of the volume and 
\begin_inset Formula $\hat{x}\in\mathbb{R}^{n}$
\end_inset

 is the ground truth volume.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/phantom-ph_mod-sl-512.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/phantom-ph_ncat-512.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/phantom-ph_mouse-512.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
The three datasets used.
 (c) shows the 
\emph on
ground truth
\emph default
 converged result from the projections.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:Phantoms"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We clip the reconstruction estimate 
\begin_inset Formula $x$
\end_inset

 at the end of each inner iteration (i.e.
 after each update step) using this function 
\begin_inset Formula 
\[
\mbox{clip}(x)=\max(0,x)
\]

\end_inset

 to get rid of negative voxel values.
 We set the number of subsets in OS-SQS to the number of projections to
 have a fair comparison with SART, since we noticed that increasing the
 number of subsets increases the convergence rate.
 All experiments in this section are run using ASTRA running on one core
 of an Intel Xeon E5-280 2.7 GHz with 64 GB RAM.
 We compare different values of 
\begin_inset Formula $\alpha$
\end_inset

, namely 0.1, 1, and 1.99.
 We compare convergence per iteration since all methods are roughly equal
 in runtime, as each outer iteration contains (roughly) one forward and
 one backward projection.
 This is confirmed in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-time-iterative"

\end_inset

.
 Note that our implementation is not optimized for any of the methods, and
 the processing time is just an indication.
\end_layout

\begin_layout Standard
Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-iteration-iterative"

\end_inset

 shows the SNR per iteration for 15 and 90 projections for 30 iterations,
 while Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-num-proj-iterative"

\end_inset

 shows the the maximum SNR over 30 iterations for different number of equally
 distributed projections from 15 to 180.
 From the figures, we make the following conclusions:
\end_layout

\begin_layout Itemize
The simulated projections closely resemble the results from the real dataset,
 which suggests that the measurement noise model is reflective of real data.
\end_layout

\begin_layout Itemize
With fewer projections (15 or 30 projections), using larger values 
\begin_inset Formula $\alpha=1.99$
\end_inset

 gives faster and better convergence.
 
\end_layout

\begin_layout Itemize
With many projections, moderate values 
\begin_inset Formula $\alpha=1$
\end_inset

 produces a fast convergence that then falls off and is overtaken by 
\begin_inset Formula $\alpha=0.1$
\end_inset

.
\end_layout

\begin_layout Itemize
SART provides the fastest convergence within a handful of iterations, and
 is consistently better for fewer projections.
 However, it is overtaken by ART and others for many projections.
 This provides the motivation to use it in the proximal framework, since
 typically the tomography solver is invoked for only a few iterations per
 outer iteration of ADMM for example 
\begin_inset CommandInset citation
LatexCommand cite
key "ramani2012splitting"

\end_inset

.
\end_layout

\begin_layout Itemize
With more projections, e.g.
 90, we notice that the SNR for a few methods go up and then down.
 This doesn't mean, however, that they are not converging.
 The objective function is the projection error, and we confirmed it is
 in fact improving even though the SNR is decreasing.
 This can be explained by the fact of the presence of noise, and that at
 some point the algorithm starts fitting the noise in the measurements 
\begin_inset CommandInset citation
LatexCommand cite
key "herman2009fundamentals"

\end_inset

.
\end_layout

\begin_layout Itemize
Even though BICAV, SIRT, and BSSART have formal proofs of convergence, their
 convergence speed per iteration is in fact much lower than SART or OS-SQS.
 
\end_layout

\begin_layout Itemize
The faster convergence and best results are achieved by SART, followed by
 ART, OS-SQS, and BICAV.
 They work better with 
\begin_inset Formula $\alpha=1$
\end_inset

 for few projections, and with 
\begin_inset Formula $\alpha=0.1$
\end_inset

 for more projections.
\end_layout

\begin_layout Itemize
Using plain iterative methods does not give acceptable results with fewer
 projections.
 Thus we focus next on using regularizers in the proximal framework with
 SART, ART, OS-SQS, and BICAV and fewer projections, namely 30 projections.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_15-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_90-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_15-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_ncat-512_nt_poisson-nl_100000.000-np_90-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_15-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_90-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Convergence of Iterative Algorithms.
 Plots show SNR per iteration.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:SNR-per-iteration-iterative"

\end_inset

Top row is for 15 projections, and bottom row is for 90 projections.
 Solid lines have 
\begin_inset Formula $\alpha=1$
\end_inset

, dashed lines have 
\begin_inset Formula $\alpha=1.99$
\end_inset

, and dotted lines have 
\begin_inset Formula $\alpha=0.1$
\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mod-sl-512_nt_poisson-nl_100000.000-np_90-p_fan_t1-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_90-p_mouse_t1-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/per_iter-ph_mouse-512_nt_gauss-nl_0.000-np_90-p_mouse_t1-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
SNR per running time for 90 projections.
 Compare with Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:SNR-per-iteration-iterative"

\end_inset

 (bottom row).
 
\begin_inset CommandInset label
LatexCommand label
name "fig:SNR-per-time-iterative"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Float figure
wide true
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/max-snr-per_num_proj-ph_mod-sl-512_nt_poisson-nl_100000.000-it_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Modified Shepp-Logan
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/max-snr-per_num_proj-ph_ncat-512_nt_poisson-nl_100000.000-it_30-p_fan-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
NCAT
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "33text%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename plots/max-snr-per_num_proj-ph_mouse-512_nt_gauss-nl_0.000-it_30-p_mouse-snr.pdf
	lyxscale 20
	width 100text%

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Mouse
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Effect of the number of projections.
 Plots show the maximum SNR achieved over 30 iterations per number of projection
s used.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:SNR-per-num-proj-iterative"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
SART Proximal Operator
\begin_inset CommandInset label
LatexCommand label
name "sec:SART-Proximal-Operator"

\end_inset


\end_layout

\begin_layout Standard
Proximal algorithms are a class of optimization algorithms that are quite
 flexible and powerful 
\begin_inset CommandInset citation
LatexCommand cite
key "combettes2011proximal,boyd2011distributed,parikh2013proximal"

\end_inset

.
 They are generally used to efficiently solve non-smooth, constrained, distribut
ed, or large scale optimization problems.
 They are more modular than other optimization problems, in the sense that
 they provide a few lines of code that depend on solving smaller conventional,
 and usually simpler, optimization problems called 
\emph on
proximal operator
\emph default
.
 The proximal operator 
\begin_inset CommandInset citation
LatexCommand cite
key "bauschke2011convex,combettes2011proximal,parikh2013proximal"

\end_inset

 for a function 
\begin_inset Formula $h(\cdot)$
\end_inset

 is a generalization of projections on convex sets, and can be thought of
 intuitively as getting closer to the optimal solution while staying close
 to the current estimate.
 Formally it is defined as 
\begin_inset Formula 
\begin{equation}
\prox_{\lambda h}(u)=\argmin_{x}h(x)+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2},\label{eq:prox-operator}
\end{equation}

\end_inset

where 
\begin_inset Formula $x,u\in\mathbb{R}^{n}$
\end_inset

 and 
\begin_inset Formula $\lambda$
\end_inset

 is a regularization parameter.
 Many proximal operators of common functions are easy to compute, and often
 admit a closed form solution.
 Computing the proximal operator of a certain function opens the way to
 solving hard optimization problems involving this function and other regulariza
tion terms e.g.
 smoothing norms or sparsity inducing norms, which otherwise is not generally
 easy.
\end_layout

\begin_layout Subsection
ART and SART
\end_layout

\begin_layout Standard
We begin by describing the SART algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1984simultaneous,andersen1989algebraic,mueller1999fast"

\end_inset

, see Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:standard-SART"

\end_inset

.
 SART is an iterative algorithm, where at each iteration the current estimate
 of the reconstructed volume is updated based on how well it fits the input
 projections.
 In particular, the update equation for each voxel 
\begin_inset Formula $x_{j}$
\end_inset

 in the volume 
\begin_inset Formula $x$
\end_inset

 is: 
\begin_inset Formula 
\begin{equation}
x_{j}^{(t+1)}=x_{j}^{(t)}+\alpha\frac{\sum_{i\in\mathcal{S}}c_{i}^{(t)}a_{ij}}{\sum_{i\in\mathcal{S}}a_{ij}},\label{eq:SART-update}
\end{equation}

\end_inset

where 
\begin_inset Formula 
\begin{equation}
c_{i}^{(t)}=\frac{p_{i}-\hat{p}_{i}^{(t)}}{\sum_{k}a_{ik}}\label{eq:residual}
\end{equation}

\end_inset

is the normalized correction factor for ray 
\begin_inset Formula $i$
\end_inset

 that measures the residual between the measured projection value 
\begin_inset Formula $p_{i}$
\end_inset

 and the current estimate at iteration 
\begin_inset Formula $t$
\end_inset

: 
\begin_inset Formula 
\begin{equation}
\hat{p}_{i}^{(t)}=\sum_{k}a_{ik}x_{k}^{(t)},\label{eq:forwardprojection}
\end{equation}

\end_inset


\begin_inset Formula $\alpha$
\end_inset

 is a relaxation parameter usually 
\begin_inset Formula $0<\alpha<2$
\end_inset

, 
\begin_inset Formula $\mathcal{S}$
\end_inset

 is a set of projection rays under consideration, and 
\begin_inset Formula $a_{ij}$
\end_inset

 is the element in row 
\begin_inset Formula $i$
\end_inset

 and column 
\begin_inset Formula $j$
\end_inset

 of the system matrix 
\begin_inset Formula $A$
\end_inset

 and defines the contribution to ray sum 
\begin_inset Formula $i$
\end_inset

 from voxel 
\begin_inset Formula $j$
\end_inset

.
 Basically the equation can be decomposed into three steps 
\begin_inset CommandInset citation
LatexCommand cite
key "mueller1999fast"

\end_inset

: 
\end_layout

\begin_layout Enumerate

\series bold
Forward projection
\series default
: computes the estimated projection 
\begin_inset Formula $\hat{p}_{i}^{(t)}$
\end_inset

 for each ray 
\begin_inset Formula $i$
\end_inset

 from the current volume 
\begin_inset Formula $x^{(t)}$
\end_inset

 (Equation
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "eq:forwardprojection"

\end_inset

).
 This corresponds to a volume rendering operation.
 
\end_layout

\begin_layout Enumerate

\series bold
Correction
\series default
: computes 
\begin_inset Formula $c_{i}^{(t)}$
\end_inset

, the normalized deviation of this estimate from the true projection 
\begin_inset Formula $p_{i}$
\end_inset

, where the correction is normalized by the contribution of this ray to
 all the voxels it goes through (Eq
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "eq:residual"

\end_inset

).
 
\end_layout

\begin_layout Enumerate

\series bold
Backprojection
\series default
: where this correction factor is distributed back to all the voxels that
 contribute to this ray sum (Eq.
\begin_inset space ~
\end_inset


\begin_inset CommandInset ref
LatexCommand ref
reference "eq:SART-update"

\end_inset

).
 
\end_layout

\begin_layout Standard
SART is an improvement to the original ART algorithm 
\begin_inset CommandInset citation
LatexCommand cite
key "gordon1970algebraic,gordon1971reconstruction"

\end_inset

.
 Unlike ART where a single iteration processes only one projection line
 
\begin_inset Formula $p_{i}$
\end_inset

 and performs the three steps above, SART combines the projection lines
 from a single projection image and applies the correction simultaneously.
 This provides faster convergence, better noise resilience, and faster computati
ons 
\begin_inset CommandInset citation
LatexCommand cite
key "andersen1989algebraic,mueller1999fast"

\end_inset

.
 In the case where the linear system is under-determined i.e.
 there are fewer equations than unknowns (
\begin_inset Formula $m<n$
\end_inset

), ART has been shown to converge to a minimum norm solution of the linear
 system describing the tomography problem 
\begin_inset CommandInset citation
LatexCommand cite
key "tanabe1971projection"

\end_inset

.
 In particular, the solution provided by ART is equivalent to the optimal
 solution of the following problem 
\begin_inset Formula 
\begin{eqnarray}
\min_{x}\left\Vert x\right\Vert _{2}^{2}\mbox{ subject to }Ax & = & p.\label{eq:ART-solution}
\end{eqnarray}

\end_inset


\end_layout

\begin_layout Standard
There has been no convergence proof for SART, although there have been proofs
 for a simplified version of SART 
\begin_inset CommandInset citation
LatexCommand cite
key "censor2002block,jiang2003convergence"

\end_inset

 that establish its convergence to a weighted least squares solution.
 In this work, we use the original SART, and assume it solves the original
 problem as ART i.e.
 it solves the minimum norm problem as defined in Eq.
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ART-solution"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement h
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
protect
\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:standard-SART"

\end_inset

Standard SART
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1]
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Require
\end_layout

\end_inset

 
\begin_inset Formula $A\in\mathbb{R}{}^{m\times n}$
\end_inset

,
\begin_inset Formula $\alpha\in\mathbb{R}$
\end_inset

, 
\begin_inset Formula $p\in\mathbb{R}{}^{m}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 Initialize: 
\begin_inset Formula $x^{(0)}=\mathbf{0}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset Formula $t=1\ldots T$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

 projection images 
\begin_inset Formula $\mathcal{S}\in\mathcal{S}_{1}\ldots\mathcal{S}_{N}$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset Formula 
\[
\hat{p}_{i}^{(t)}=\sum_{k}a_{ik}x_{k}^{(t)}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
c_{i}^{(t)}=\frac{p_{i}-\hat{p}_{i}^{(t)}}{\sum_{k}a_{ik}}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{\sum_{i\in\mathcal{S}}c_{i}^{(t)}a_{ij}}{\sum_{i\in\mathcal{S}}a_{ij}}\mbox{ for }j=1\ldots n,
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Return
\end_layout

\end_inset

 volume reconstruction 
\begin_inset Formula $x\in\mathbb{R}{}^{n}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Proximal Operator
\end_layout

\begin_layout Standard
In this work we are interested in finding the volume that minimizes the
 squared fit error 
\begin_inset Formula $h(x)=\Vert Ax-p\Vert_{2}^{2}$
\end_inset

 i.e.
 that solves the minimization problem 
\begin_inset Formula 
\[
\min_{x}\Vert Ax-p\Vert_{2}^{2}.
\]

\end_inset

This is the standard goodness-of-fit measure for tomography reconstruction
 problems, and is more general and handles cases where the system is over-
 or under-determined.
 The proximal operator for 
\begin_inset Formula $h(x)$
\end_inset

 is defined as 
\begin_inset Formula 
\begin{equation}
\mbox{prox}_{\lambda h}(u)=\argmin_{x}\Vert Ax-p\Vert_{2}^{2}+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}.\label{eq:SART-prox-1}
\end{equation}

\end_inset

We will use SART to solve this optimization problem.
 Recall that SART solves a minimum norm problem as in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ART-solution"

\end_inset

.
 Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:SART-prox-1"

\end_inset

 is equivalent to solving the following problem 
\begin_inset Formula 
\begin{equation}
\min_{x}2\lambda\Vert Ax-p\Vert_{2}^{2}+\Vert x-u\Vert_{2}^{2}.\label{eq:SART-prox-2}
\end{equation}

\end_inset

We will introduce new variables as follows: let 
\begin_inset Formula $y=\sqrt{2\lambda}(p-Ax)$
\end_inset

 and 
\begin_inset Formula $z=x-u$
\end_inset

.
 The problem now becomes 
\begin_inset Formula 
\begin{eqnarray}
\min_{y,z} & \Vert y\Vert_{2}^{2}+\Vert z\Vert_{2}^{2}\nonumber \\
\mbox{subject to} & y+\sqrt{2\lambda}Az=\sqrt{2\lambda}(p-Au).\label{eq:SART-prox-3}
\end{eqnarray}

\end_inset

Rewriting Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:SART-prox-3"

\end_inset

 we arrive at the system 
\begin_inset Formula 
\begin{eqnarray*}
\mbox{\ensuremath{\min}}_{y,z} & \left\Vert \left[\begin{array}{c}
y\\
z
\end{array}\right]\right\Vert _{2}^{2}\\
\mbox{subject to} & \left[\begin{array}{cc}
I & \sqrt{2\lambda}A\end{array}\right]\left[\begin{array}{c}
y\\
z
\end{array}\right]=\sqrt{2\lambda}\left(p-Au\right)
\end{eqnarray*}

\end_inset

which can be written as 
\begin_inset Formula 
\begin{eqnarray*}
\mbox{\ensuremath{\min}}_{\tilde{x}} & \left\Vert \tilde{x}\right\Vert _{2}^{2}\\
\mbox{subject to} & \tilde{A}\tilde{x}=\tilde{p},
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $\tilde{x}\in\mathbb{R}^{m+n}$
\end_inset

, 
\begin_inset Formula $\tilde{A}\in\mathbb{R}^{m\times m+n}$
\end_inset

, and 
\begin_inset Formula $\tilde{p}\in\mathbb{R}^{m}$
\end_inset

.
 This is now an under-determined linear system, and can be solved using
 SART as in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:ART-solution"

\end_inset

.
\end_layout

\begin_layout Subsection
Algorithm
\end_layout

\begin_layout Standard
Although we introduced new variables 
\begin_inset Formula $y$
\end_inset

 and 
\begin_inset Formula $z$
\end_inset

 and increased the dimensionality of the problem from 
\begin_inset Formula $n$
\end_inset

 to 
\begin_inset Formula $n+m$
\end_inset

, we can solve the modified SART efficiently with very little computational
 overhead.
 Instead of solving SART explicitly for the optimal 
\begin_inset Formula $y^{\star}$
\end_inset

and 
\begin_inset Formula $z^{\star}$
\end_inset

, we can manipulate the algorithm to solve directly for the optimal 
\begin_inset Formula $x^{\star}.$
\end_inset

 In particular, the Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:SART-update"

\end_inset

 for the augmented system 
\begin_inset Formula $\tilde{A}\tilde{x}=\tilde{p}$
\end_inset

 becomes (by substituting all variables) 
\begin_inset Formula 
\begin{eqnarray}
\tilde{x}_{j}^{(0)} & = & \mathbf{0},\nonumber \\
\tilde{x}_{j}^{(t+1)} & = & \tilde{x}_{j}^{(t)}+\alpha\frac{\sum_{i\in\mathcal{S}}\frac{\tilde{p}_{i}-\sum_{k}\tilde{a}_{ik}\tilde{x}_{k}^{(t)}}{\sum_{k}\tilde{a}_{ik}}\tilde{a}_{ij}}{\sum_{i\in S}\tilde{a}_{ij}},\label{eq:SART-proximal-update-1}
\end{eqnarray}

\end_inset

which can be expanded in terms of 
\begin_inset Formula $y$
\end_inset

, 
\begin_inset Formula $z$
\end_inset

, and 
\begin_inset Formula $A$
\end_inset

 as 
\begin_inset Formula 
\begin{eqnarray*}
y_{j}^{(t+1)} & = & y_{j}^{(t)}+\frac{\alpha\sum_{i\in\mathcal{S}}\frac{\tilde{p}_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}z_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\delta_{ij}}{1},\\
z_{j}^{(t+1)} & = & z_{j}^{(t)}+\alpha\frac{\sum_{i\in\mathcal{S}}\frac{\tilde{p}_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}z_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\sqrt{2\lambda}a_{ij}}{\sqrt{2\lambda}\sum_{i\in S}a_{ij}},
\end{eqnarray*}

\end_inset

where 
\begin_inset Formula $\delta_{ij}=1$
\end_inset

 when 
\begin_inset Formula $i=j$
\end_inset

 and 0 otherwise.
 Using the fact that 
\begin_inset Formula $z=x-u$
\end_inset

 and simplifying we arrive at 
\begin_inset Formula 
\begin{eqnarray*}
y_{j}^{(t+1)} & = & y_{j}^{(t)}+\alpha\sum_{i\in S}\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\delta_{ij},\\
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{\sum_{i\in S}\frac{\sqrt{2\lambda}p_{i}-\sqrt{2\lambda}\sum_{k}a_{ik}x_{k}^{(t)}-y_{i}^{(t)}}{\sqrt{2\lambda}\sum_{k}a_{ik}+1}\sqrt{2\lambda}a_{ij}}{\sqrt{2\lambda}\sum_{i\in S}a_{ij}}.
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:SART-Proximal-Operator"

\end_inset

 summarizes the steps for the modified SART to solve the proximal operator.
 We note the following: 
\end_layout

\begin_layout Enumerate
The initialization is different since we need to initialize 
\begin_inset Formula $y$
\end_inset

 and 
\begin_inset Formula $x$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
The update for 
\begin_inset Formula $y$
\end_inset

 is very fast because only one index 
\begin_inset Formula $y_{j}$
\end_inset

 is updated for every projection pixel 
\begin_inset Formula $i=j$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
The update for 
\begin_inset Formula $x$
\end_inset

 is very similar to standard SART with the exception of the term 
\begin_inset Formula $y_{i}^{(t)}$
\end_inset

 in the formula for 
\begin_inset Formula $c_{i}^{(t)}.$
\end_inset

 
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
protect
\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:SART-Proximal-Operator"

\end_inset

SART Proximal Operator
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1]
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Require
\end_layout

\end_inset

 
\begin_inset Formula $A\in\mathbb{R}{}^{m\times n}$
\end_inset

, 
\begin_inset Formula $u\in\mathbb{R}{}^{n}$
\end_inset

, 
\begin_inset Formula $\lambda\in\mathbb{R}$
\end_inset

, 
\begin_inset Formula $\alpha\in\mathbb{R}$
\end_inset

, 
\begin_inset Formula $p\in\mathbb{R}{}^{m}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset


\begin_inset Formula $p=\sqrt{2\lambda}p$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset


\begin_inset Formula $A=\sqrt{2\lambda}A$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 Initialize 
\begin_inset Formula 
\begin{eqnarray*}
y^{(0)} & = & 0\\
x^{(0)} & = & u
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset Formula $t=1\ldots T$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset

 projections 
\begin_inset Formula $\mathcal{S}\in\mathcal{S}_{1}\ldots\mathcal{S}_{N}$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset Formula 
\[
y_{j}^{(t+1)}=y_{j}^{(t)}+\alpha c_{j}^{(t)}\mbox{ for }j\in\mathcal{S}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
\hat{p}_{i}^{(t)}=\sum_{k}a_{ik}x_{k}^{(t)}+y_{i}^{(t)}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\[
c_{i}^{(t)}=\frac{p_{i}-\hat{p}_{i}^{(t)}}{\sum_{k}a_{ik}+1}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{eqnarray*}
x_{j}^{(t+1)} & = & x_{j}^{(t)}+\alpha\frac{\sum_{i\in\mathcal{S}}c_{i}^{(t)}a_{ij}}{\sum_{i\in\mathcal{S}}a_{ij}}\mbox{ for }j=1\ldots n,
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Return
\end_layout

\end_inset

 volume reconstruction 
\begin_inset Formula $x\in\mathbb{R}{}^{n}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Section
Proximal Framework
\begin_inset CommandInset label
LatexCommand label
name "sec:Proximal-Framework"

\end_inset


\end_layout

\begin_layout Subsection
Proximal Algorithm
\end_layout

\begin_layout Standard
The overall problem we are interested in solving is a regularized data fitting
 problem.
 In particular, the objective function we are interested in minimizing is
 
\begin_inset Formula 
\[
f(x)+g(Kx),
\]

\end_inset

where 
\begin_inset Formula $f(\cdot)$
\end_inset

 is a data fitting term that measures how much the solution fits the data,
 
\begin_inset Formula $g(\cdot)$
\end_inset

 is a regularization term that imposes constraints on acceptable solutions
 through multiplication by an arbitrary matrix 
\begin_inset Formula $K$
\end_inset

, and usually includes another parameter 
\begin_inset Formula $\sigma$
\end_inset

 that trades off the data and the regularization term i.e.
 it takes the form 
\begin_inset Formula 
\[
g(Kx)=\sigma\tilde{g}(Kx).
\]

\end_inset

For example, in our case, 
\begin_inset Formula 
\[
f(x)=\Vert Ax-p\Vert_{2}^{2}
\]

\end_inset

which is a measure of how well the reconstruction fits the given projection
 images.
\end_layout

\begin_layout Standard
For the regularization part, we can have several functions.
 For example: 
\end_layout

\begin_layout Itemize
the simplest is to regularize the 
\begin_inset Formula $\ell_{2}$
\end_inset

 norm of the volume i.e.
 
\begin_inset Formula 
\[
g(Kx)=\sigma\tilde{g}(Kx)=\sigma\Vert x\Vert_{2}^{2}\mbox{ where }K=I.
\]

\end_inset


\end_layout

\begin_layout Itemize
Another example is the 
\begin_inset Formula $\ell_{1}$
\end_inset

 norm if we have reason to believe that the volume should have few nonzero
 voxels i.e.
 
\begin_inset Formula 
\[
g(Kx)=\sigma\Vert x\Vert_{1}=\sum_{i}\vert x_{i}\vert.
\]

\end_inset


\end_layout

\begin_layout Itemize
One more example is the Anisotropic Total Variation 
\begin_inset CommandInset citation
LatexCommand cite
key "sidky2008image,beck2009bfast,chambolle2010introduction,nien2015fast"

\end_inset

, which intuitively is the 
\begin_inset Formula $\ell_{1}$
\end_inset

 norm of the gradient of the volume i.e.
 
\begin_inset Formula 
\[
g(Kx)=\sigma\Vert\nabla x\Vert_{1},
\]

\end_inset

where in this case the matrix 
\begin_inset Formula $K\in\mathbb{R}^{3n\times n}$
\end_inset

 is the matrix of first-order forward derivatives.
 
\end_layout

\begin_layout Standard
In order to solve this problem, we will use proximal algorithms, namely
 the first-order primal-dual algorithm proposed by Chambolle and Pock (hencefort
h referred to as the CP algorithm) 
\begin_inset CommandInset citation
LatexCommand cite
key "chambolle2011first"

\end_inset

 summarized in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:CP-algorithm"

\end_inset

.
 For the algorithm to work, we need two proximal operators: 
\end_layout

\begin_layout Itemize
The proximal operator for the first function 
\begin_inset Formula 
\[
\prox_{\lambda f}(u)=\argmin_{x}f(x)+\frac{1}{2\lambda}\Vert x-u\Vert_{2}^{2}.
\]

\end_inset


\end_layout

\begin_layout Itemize
The proximal operator for the convex conjugate 
\begin_inset CommandInset citation
LatexCommand cite
key "boyd2004convex"

\end_inset

 function 
\begin_inset Formula $g^{*}(\cdot)$
\end_inset

 of 
\begin_inset Formula $g(\cdot)$
\end_inset

 defined as 
\begin_inset Formula 
\[
\prox_{\mu g^{*}}(u)=\argmin_{x}g^{*}(x)+\frac{1}{2\mu}\Vert x-u\Vert_{2}^{2},
\]

\end_inset

where 
\begin_inset Formula $g^{*}(\cdot)$
\end_inset

 is defined as 
\begin_inset Formula 
\[
g^{*}(u)=\sup_{x}u^{T}x-g(x).
\]

\end_inset

Computing this conjugate proximal operator actually is quite easy if we
 know the proximal operator for 
\begin_inset Formula $g(\cdot),$
\end_inset

 since using Moreau's decomposition 
\begin_inset CommandInset citation
LatexCommand cite
key "parikh2013proximal"

\end_inset

 we have 
\begin_inset Formula 
\begin{equation}
\prox_{\mu g^{*}}(u)=u-\mu\prox_{\frac{1}{\mu}g}(\frac{u}{\mu}).\label{eq:moreau-decomposition}
\end{equation}

\end_inset

It can also be shown that the proximal operator for 
\begin_inset Formula $g^{*}(\cdot)$
\end_inset

 is related to the proximal operator for 
\begin_inset Formula $\tilde{g}^{*}(\cdot)$
\end_inset

 by 
\begin_inset Formula 
\begin{equation}
\prox_{\mu g^{*}}(u)=\sigma\prox_{(\mu/\sigma)\tilde{g}^{*}}\left(\frac{u}{\sigma}\right),\label{eq:prox-g-conj-with-sigma}
\end{equation}

\end_inset

so the 
\begin_inset Formula $z-$
\end_inset

step of Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:CP-algorithm"

\end_inset

 can be written as 
\begin_inset Formula 
\[
z^{(t+1)}=\sigma\prox_{(\mu/\sigma)\tilde{g}^{*}}\left(\frac{z^{(t)}+\mu K\bar{x}^{(t)}}{\sigma}\right).
\]

\end_inset


\end_layout

\begin_layout Standard
Using different regularization functions 
\begin_inset Formula $g(\cdot)$
\end_inset

 and matrices 
\begin_inset Formula $K$
\end_inset

, we can plug in different priors based on our prior information of how
 the reconstructed volume should look like.
\end_layout

\begin_layout Standard
\begin_inset Float algorithm
placement h
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
protect
\end_layout

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset CommandInset label
LatexCommand label
name "alg:CP-algorithm"

\end_inset

CP Algorithm (Chambolle-Pock Primal-Dual)
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
begin{algorithmic}[1]
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Require
\end_layout

\end_inset

 
\begin_inset Formula $K\in\mathbb{R}{}^{d\times n}$
\end_inset

, 
\begin_inset Formula $\theta\in[0,1]$
\end_inset

, 
\begin_inset Formula $\lambda,\mu$
\end_inset

 such that 
\begin_inset Formula $\mu\lambda\Vert K\Vert^{2}<1$
\end_inset

, 
\begin_inset Formula $\sigma\in\mathbb{R}$
\end_inset

, initial values 
\begin_inset Formula $x^{(0)}\in\mathbb{R}^{n}$
\end_inset

 and 
\begin_inset Formula $z^{(0)}\in\mathbb{R}^{d}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
State
\end_layout

\end_inset

 Initialize 
\begin_inset Formula 
\[
\bar{x}^{(0)}=x^{(0)}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
ForAll
\end_layout

\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

{
\end_layout

\end_inset


\begin_inset Formula $t=1\ldots T$
\end_inset

 
\begin_inset ERT
status collapsed

\begin_layout Plain Layout

}
\end_layout

\end_inset

 
\begin_inset Formula 
\begin{eqnarray*}
z^{(t+1)} & = & \prox_{\mu g^{*}}\left(z^{(t)}+\mu K\bar{x}^{(t)}\right)\\
x^{(t+1)} & = & \prox_{\lambda f}\left(x^{(t)}-\lambda K^{T}z^{(t+1)}\right)\\
\bar{x}^{(t+1)} & = & x^{(t+1)}+\theta(x^{(t+1)}-x^{(t)})
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
EndFor
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
Return
\end_layout

\end_inset

 
\begin_inset Formula $x^{(T)}\in\mathbb{R}{}^{n}$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset ERT
status collapsed

\begin_layout Plain Layout


\backslash
end{algorithmic}
\end_layout

\end_inset

 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Details
\end_layout

\begin_layout Standard
We use our SART proximal operator detailed in Algorithm 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:SART-Proximal-Operator"

\end_inset

 for solving 
\begin_inset Formula $\prox_{f}(\cdot)$
\end_inset

 required in the CP algorithm.
 The implementation of 
\begin_inset Formula $\prox_{g^{*}}(\cdot)$
\end_inset

 depends on the choice of prior.
 We experiment with the following priors:
\end_layout

\begin_layout Subsubsection
Anisotropic TV (ATV)
\end_layout

\begin_layout Standard
This prior is defined as: 
\begin_inset Formula 
\begin{equation}
h(x)=\sum_{ijk}{\scriptstyle \left|x_{i+1,j,k}-x_{i,j,k}\right|+\left|x_{i,j+1,k}-x_{i,j,k}\right|+\left|x_{i,j,k+1}-x_{i,j,k}\right|},\label{eq:ATV}
\end{equation}

\end_inset

where 
\begin_inset Formula $x_{i,j,k}$
\end_inset

 is the voxel value at position 
\begin_inset Formula $(i,j,k)$
\end_inset

.
 This can be represented as 
\begin_inset Formula $\tilde{g}(Kx)$
\end_inset

, where 
\begin_inset Formula $g(\cdot)=\Vert\cdot\Vert_{1}$
\end_inset

 is the 
\begin_inset Formula $\ell_{1}$
\end_inset

 norm and 
\begin_inset Formula $K=D\in\mathbb{R}^{3n\times n}$
\end_inset

 is the forward difference matrix defined as 
\begin_inset Formula 
\begin{eqnarray}
D_{ev} & = & \begin{cases}
-1 & \mbox{if }v=i\\
1 & \mbox{if }v=j\\
0 & \mbox{otherwise}
\end{cases},\label{eq:forward-diff-matrix-D}
\end{eqnarray}

\end_inset

where we consider a graph defined on the volume such that we have 
\begin_inset Formula $n$
\end_inset

 vertices (voxels) and 
\begin_inset Formula $3n$
\end_inset

 edges (connecting each voxel to its six neighbors, replicating voxels at
 the edge).
 The matrix 
\begin_inset Formula $D$
\end_inset

 is a representation of this graph, where each row corresponds to one edge,
 and each column to one vertex.
 The value at row 
\begin_inset Formula $e$
\end_inset

 and column 
\begin_inset Formula $v$
\end_inset

 is given by Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:forward-diff-matrix-D"

\end_inset

 above.
 The proximal operator of 
\begin_inset Formula $\tilde{g}^{*}(\cdot)$
\end_inset

 can be shown to be 
\begin_inset CommandInset citation
LatexCommand cite
key "parikh2013proximal"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\prox_{\mu\tilde{g}^{*}}(u)=P_{B_{\infty}}(u)=\begin{cases}
1 & u>1\\
u & \vert u\vert\le1\\
-1 & u<-1
\end{cases},\label{eq:l1-prox-conj}
\end{equation}

\end_inset

where the operations are component-wise, and is equivalent to the projection
 on the unit ball 
\begin_inset Formula $B_{\infty}$
\end_inset

 of the 
\begin_inset Formula $\ell_{\infty}$
\end_inset

 norm.
 Note that we do not need to store the matrix 
\begin_inset Formula $D$
\end_inset

, and multiplication by 
\begin_inset Formula $D$
\end_inset

 (computing the gradient) or by 
\begin_inset Formula $D^{T}$
\end_inset

 (computing the divergence) can be efficiently computed on-the-fly 
\begin_inset CommandInset citation
LatexCommand cite
key "esser2010general"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Isotropic TV (ITV)
\end_layout

\begin_layout Standard
This prior is defined as: 
\begin_inset Formula 
\[
h(x)=\sum_{ijk}{\scriptstyle \sqrt{\left|x_{i+1,j,k}-x_{i,j,k}\right|^{2}+\left|x_{i,j+1,k}-x_{i,j,k}\right|^{2}+\left|x_{i,j,k+1}-x_{i,j,k}\right|^{2}}},
\]

\end_inset

where it sums the magnitude of the gradient at each voxel.
 Using the same matrix 
\begin_inset Formula $D$
\end_inset

 defined in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:forward-diff-matrix-D"

\end_inset

 and defining a new matrix 
\begin_inset Formula $E\in\mathbb{R}^{3n\times n}$
\end_inset

 that denotes the positions of the forward differences 
\begin_inset CommandInset citation
LatexCommand cite
key "esser2010general"

\end_inset

 such that 
\begin_inset Formula 
\[
E_{ev}=\begin{cases}
1 & \mbox{if }D_{ev}=-1\\
0 & \mbox{otherwise}
\end{cases},
\]

\end_inset

we can define the function 
\begin_inset Formula $h(x)$
\end_inset

 as a norm 
\begin_inset Formula $\Vert u\Vert_{E}$
\end_inset

 for 
\begin_inset Formula $u=Dx\in\mathbb{R}^{3n}$
\end_inset

 defined as 
\begin_inset Formula 
\[
\Vert w\Vert_{E}=\Vert\sqrt{E^{T}w^{2}}\Vert_{1}=\sum_{v}\Vert w^{v}\Vert_{2},
\]

\end_inset

where the square root and square functions are component-wise, and 
\begin_inset Formula $w^{v}$
\end_inset

 is the gradient at voxel 
\begin_inset Formula $v=(i,j,k)$
\end_inset

 i.e.
 
\begin_inset Formula 
\[
w^{v}=\left[\begin{array}{c}
x_{i+1,j,k}-x_{i,j,k}\\
x_{i,j+1,k}-x_{i,j,k}\\
x_{i,j,k+1}-x{}_{i,j,k}
\end{array}\right].
\]

\end_inset


\end_layout

\begin_layout Standard
Now we can express the ITV prior 
\begin_inset Formula $h(x)$
\end_inset

 in terms of the 
\begin_inset Formula $\Vert u\Vert_{E}$
\end_inset

 norm as 
\begin_inset Formula 
\[
h(x)=\Vert Dx\Vert_{E}=g(Dx)\mbox{ where }\tilde{g}(u)=\Vert u\Vert_{E}.
\]

\end_inset

The proximal operator for 
\begin_inset Formula $g^{*}(\cdot)$
\end_inset

 can be shown to be 
\begin_inset CommandInset citation
LatexCommand cite
key "esser2010general"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\prox_{\mu\tilde{g}^{*}}(u)=P_{B^{*}}(u)=\frac{u}{E\max\left(\sqrt{E^{T}u^{2}},1\right)}\label{eq:ITV-prox}
\end{equation}

\end_inset

which is the projection on the unit ball 
\begin_inset Formula $B^{*}$
\end_inset

 of the dual norm 
\begin_inset Formula $\Vert u\Vert_{E^{*}}$
\end_inset

, and where the division and max operations are performed component-wise.
 Intuitively, this scales each voxel by the magnitude of its gradient if
 it's greater than unity.
 Similar to ATV, we don't need to explicitly store the matrix 
\begin_inset Formula $E$
\end_inset

, and multiplication by 
\begin_inset Formula $E$
\end_inset

 can be computed efficiently on-the-fly.
\end_layout

\begin_layout Subsubsection
Sum of Absolute Differences (SAD) 
\end_layout

\begin_layout Standard
This prior is defined as: 
\begin_inset Formula 
\begin{equation}
h(x)=\sum_{ijk}\sum_{x_{n}\in N(x_{i,j,k})}\left|x_{n}-x_{i,j,k}\right|,\label{eq:SAD}
\end{equation}

\end_inset

where 
\begin_inset Formula $N(x_{i,j,k})$
\end_inset

 is the 
\begin_inset Formula $3\times3$
\end_inset

 neighborhood around voxel 
\begin_inset Formula $x_{i,j,k}$
\end_inset

 (excluding voxel 
\begin_inset Formula $x_{i,j,k}$
\end_inset

 itself).
 It can be seen as an extension to the ATV prior, just with a different
 matrix 
\begin_inset Formula $D$
\end_inset

 where more edges are considered for every voxel instead of just three.
 Hence its proximal operator is similar to Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq:l1-prox-conj"

\end_inset

.
 It has been shown 
\begin_inset CommandInset citation
LatexCommand cite
key "gregson2012stochastic"

\end_inset

 to produce excellent results in stochastic tomography reconstruction.
\end_layout

\begin_layout Section
Experiments
\begin_inset CommandInset label
LatexCommand label
name "sec:Experiments"

\end_inset


\end_layout

\begin_layout Standard
We run two kinds of experiments: (a) on simulated data using the Shepp-Logan
 phantom 
\begin_inset CommandInset citation
LatexCommand cite
key "shepp1974fourier"

\end_inset

; and (b) on real data using the standard RabbitCT benchmark 
\begin_inset CommandInset citation
LatexCommand cite
key "rohkohl2009rabbitct"

\end_inset

 and the Lynx dataset.
 All experiments are executed on a machine with two Intel Xeon X5650 processors
 (24 cores overall) and 48 GB of RAM.
 The code is implemented in C++ and is available at 
\begin_inset Flex Flex:URL
status collapsed

\begin_layout Plain Layout

https://github.com/prilemon/ProxiSART
\end_layout

\end_inset

.
 Our implementation of SART uses the Kaiser-Bessel kernels 
\begin_inset CommandInset citation
LatexCommand cite
key "mueller1998fast"

\end_inset

 (with a radius of 2 voxels) for more accurate and smooth interpolation
 in the forward and back projection steps.
 We also employ the slice-by-slice mechanism to speed up the (back)projection
 steps 
\begin_inset CommandInset citation
LatexCommand cite
key "mueller1998fast"

\end_inset

.
\end_layout

\begin_layout Standard
We evaluate our results using two metrics: (a) Signal-to-noise Ratio (SNR);
 and (b) Structural Similarity Index (SSIM) 
\begin_inset CommandInset citation
LatexCommand cite
key "wang2004image"

\end_inset

.
 The first metric is a standard one used for measuring the quality of volume
 reconstruction compared to the ground truth volume, while the second gives
 more perceptually-related reconstruction measure.
\end_layout

\begin_layout Standard
We run different versions of our algorithms with different priors, namely:
 
\end_layout

\begin_layout Itemize
Our implementation of plain SART with no priors as in Alg.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "alg:standard-SART"

\end_inset

 (PlainSART).
 
\end_layout

\begin_layout Itemize
ProxiSART with Anisotropic Total Variation using CP (PSART-ATV) 
\end_layout

\begin_layout Itemize
ProxiSART with Isotropic Total Variation using CP (PSART-ITV).
 
\end_layout

\begin_layout Itemize
ProxiSART with Sum of Absolute Differences using CP (PSART-SAD).
 
\end_layout

\begin_layout Standard
We compare results from our framework to state-of-the-art algorithms and
 comparable implementations in RTK, namely: 
\end_layout

\begin_layout Itemize
Cone Beam Filtered Back Projection (RTK-FDK) 
\begin_inset CommandInset citation
LatexCommand cite
key "feldkamp1984practical"

\end_inset

.
 
\end_layout

\begin_layout Itemize
Plain SART with no priors (RTK-SART).
 
\end_layout

\begin_layout Itemize
ADMM with ATV prior (RTK-ADMM) using Conjugate Gradient (CG) 
\begin_inset CommandInset citation
LatexCommand cite
key "mory2012ecg"

\end_inset

.
 
\end_layout

\begin_layout Standard
For choosing the hyper parameters in all the algorithms, we experiment with
 a range of combinations and pick the one with the best performance (SNR).
\end_layout

\begin_layout Subsection
Simulated Dataset
\end_layout

\begin_layout Standard
We run experiments on a 
\begin_inset Formula $128\times128\times128$
\end_inset

 3D Shepp-Logan volume with voxel size of 
\begin_inset Formula $1\times1\times1$
\end_inset

 mm.
 The distance between the cone beam source and the detector matrix is 955
 mm, while that between the source and the object isocenter is 500 mm.
 The detector panel has 
\begin_inset Formula $512\times512$
\end_inset

 pixels with 
\begin_inset Formula $1\times1$
\end_inset

 mm size.
 We focus on cases where noise might prevent accurate reconstruction.
 Therefore, we compare reconstruction using different numbers of projection
 images; namely 30, 45, 60, and 90 images equally distributed across the
 
\begin_inset Formula $360^{\circ}$
\end_inset

 angular range.
 We also compare injecting zero-mean additive Gaussian noise with different
 standard deviations; namely 0.05, 0.2, 0.5, and 0.75.
 The projections were generated using RTK 
\begin_inset CommandInset citation
LatexCommand cite
key "rit2014reconstruction"

\end_inset

.
 We set the number of SART and CG iterations at 2 in every step for our
 algorithms and for RTK-ADMM, respectively.
 The relaxation coefficient 
\begin_inset Formula $\alpha$
\end_inset

 in SART is set to 0.5.
\end_layout

\begin_layout Standard
Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simulation-Results:-Effect-Num-Proj"

\end_inset

 shows the SNR and SSIM for the different reconstruction algorithms when
 varying the number of projections.
 Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simulation-Results-Sample-Num-Proj"

\end_inset

 shows a sample slice from the reconstructed volume for the different algorithms
 and different numbers of projections.
 Similarly, Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simulation-Results:-Effect-Noise"

\end_inset

 shows the SNR and SSIM for the different algorithms with different amounts
 of additive Gaussian noise, while Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simulation-Results-Sample-Noise"

\end_inset

 shows a sample slice from the respective reconstructions (we omit results
 for PSART-ATV because they are almost identical to PSART-ITV).
 To assess the speed of convergence, Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simulation-Speed-of-convergence"

\end_inset

 shows the SNR as a function of the number of iterations in the reconstruction,
 with 60 projections and 
\begin_inset Formula $\sigma=0.75$
\end_inset

 noise.
\end_layout

\begin_layout Standard
We note the following: 
\end_layout

\begin_layout Itemize
Using priors (ATV, ITV, or SAD) consistently gives better accuracy and faster
 convergence, specially with noisy measurements or using very few projections.
 
\end_layout

\begin_layout Itemize
Our implementation of SART converges faster and gives lower error than RTK-SART.
 One reason might be the better interpolation filter (Kaiser-Bessel vs.
 tri-linear in RTK) we use.
 
\end_layout

\begin_layout Itemize
Our ProxiSART reconstructions consistently give better results than the
 equivalent RTK-ADMM.
 
\end_layout

\begin_layout Itemize
ITV and ATV priors give almost identical results, hence we include only
 the visualizations for ITV in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simulation-Results-Sample-Num-Proj"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Simulation-Results-Sample-Noise"

\end_inset

.
 
\end_layout

\begin_layout Itemize
PSART-SAD produces the best results in terms of visualization quality, SNR,
 and convergence speed, confirming earlier results about the SAD regularizer
 
\begin_inset CommandInset citation
LatexCommand cite
key "gregson2012stochastic"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Real Datasets
\end_layout

\begin_layout Standard
We run another round of experiments on a real datasets, namely: (a) the
 RabbitCT 
\begin_inset Foot
status open

\begin_layout Plain Layout
available from 
\begin_inset Flex Flex:URL
status open

\begin_layout Plain Layout

http://rabbitct.com
\end_layout

\end_inset


\end_layout

\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "rohkohl2009rabbitct"

\end_inset

 ; and (b) the Lynx Dataset 
\begin_inset Foot
status collapsed

\begin_layout Plain Layout
available from 
\begin_inset Flex Flex:URL
status collapsed

\begin_layout Plain Layout

http://goo.gl/3NhbKq
\end_layout

\end_inset


\end_layout

\end_inset

.
 The RabbitCT is a CT scan of a rabbit used for benchmarking the speed of
 tomographic reconstruction algorithms.
 It contains 496 projections obtained using a C-arm system from Siemens
 Artis Zee acquired on a 
\begin_inset Formula $200^{\circ}$
\end_inset

 circular short-scan trajectory.
 We use 62 (=496/8) equally-distributed projections.
 The size of the projection image is 
\begin_inset Formula $1248\times960$
\end_inset

 pixels with isotropic resolution of 
\begin_inset Formula $0.32$
\end_inset

 mm/pixel.
 The source to detector distance is 871.1088 mm and the source to isocenter
 is 600 mm.
 We used a volume of size 
\begin_inset Formula $128\times128\times128$
\end_inset

 voxels and 2 mm spacing.
\end_layout

\begin_layout Standard
The Lynx dataset is a CT scan of a lynx skull using an Agfa Orthoregular
 intensifier screen.
 We use 90 equally-distributed projections.
 The source to detector distance is 784.86 mm and the source to isocenter
 distance is 250 mm.
 The detector size is 
\begin_inset Formula $546\times348$
\end_inset

 pixels with 
\begin_inset Formula $1\times1$
\end_inset

 mm spacings.
 The volume size is 
\begin_inset Formula $350\times260\times260$
\end_inset

 voxels with 
\begin_inset Formula $0.5\times0.5\times0.5$
\end_inset

 mm spacing.
\end_layout

\begin_layout Standard
We use 20 iterations for both ADMM and CP (with 2 iterations for SART and
 CG, respectively).
 Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Real-Results-Sample-Rabbit"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Real-Results-Sample-Lynx"

\end_inset

 shows sample slices from reconstruction of the RabbitCT and the Lynx datasets,
 respectively.
 We notice that using ProxiSART with ITV or SAD provides better reconstructions
 with less artifacts than FDK or plain SART.
\end_layout

\begin_layout Section
Conclusions
\begin_inset CommandInset label
LatexCommand label
name "sec:Discussion-and-Conclusion"

\end_inset


\end_layout

\begin_layout Standard
We presented ProxiSART, a flexible proximal framework for robust 3D cone
 beam reconstruction.
 We derived the proximal operator for the data fitting sub-problem using
 the powerful SART algorithm.
 We ran experiments comparing our framework with the popular RTK open-source
 software toolkit, both on real and simulated datasets, using different
 standard and non-standard priors.
 We showed the robustness of our algorithms in terms of reconstruction quality
 and fewer iterations till convergence in the presence of noise and using
 fewer projections.
 Next, we plan on investigating using other more powerful priors, specifically
 non-local TV; and using the method with other noise models than the Gaussian
 noise model, for example the Poisson noise model.
\end_layout

\begin_layout Section
Acknowledgments
\end_layout

\begin_layout Standard
This work was supported by KAUST baseline and research center funding.
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "I:/Documents/Research/Papers/papers"
options "bibtotoc,ieeetr"

\end_inset


\end_layout

\end_body
\end_document
